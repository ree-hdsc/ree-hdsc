{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b488d16-7562-4dbf-be6a-a8c10ded2365",
   "metadata": {},
   "source": [
    "# HTR Training\n",
    "\n",
    "Combine different sets of documents, train HTR on Transkribus and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299d22e-ab21-4322-9013-3a4d2e51c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import regex\n",
    "import shutil\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "from scripts.read_transkribus_files import get_text_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a6e9d-384f-4ce4-a7fb-17687e466915",
   "metadata": {},
   "source": [
    "## 1. Label and check available training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c2a5c-8236-4ace-86ec-9b39b89e58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRS = [ # \"tmp/1221135/Trainingssample_\", \n",
    "              # \"tmp/1339924/Training_extra\",\n",
    "              # \"tmp/1342783/Validation_set\",\n",
    "              # \"tmp/1339925/Test_set\",\n",
    "              # \"tmp/1339926/Validation_extra\",\n",
    "              # \"tmp/1480298/Sample_known_V2(verbeterd)\",\n",
    "              # \"tmp/1372935/Sample_regex\",\n",
    "              # \"tmp/1616639/Sample_test_1\",\n",
    "              \"tmp/1586842/Training_set\",\n",
    "              \"tmp/1586854/Validation_set\",\n",
    "              \"tmp/1609526/Training_set_2\",\n",
    "              \"tmp/1609530/Validation_set_2\",\n",
    "              \"tmp/1616742/Sample_three-column\"\n",
    "            ]\n",
    "YEAR_FILES = [ os.path.basename(file_name) + \"_years.csv\" for file_name in DATA_DIRS ]\n",
    "USAGE_FILES = [ os.path.basename(file_name) + \"_usage.csv\" for file_name in DATA_DIRS ]\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f639e80-1043-4ffd-8c37-68ef0aaadd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_years_of_files(data_dirs=DATA_DIRS, year_files=YEAR_FILES):\n",
    "    for data_dir_id in range(0, len(data_dirs)):\n",
    "        last_year = \"\"\n",
    "        file_counter = 0\n",
    "        data_dir = data_dirs[data_dir_id]\n",
    "        year_file = year_files[data_dir_id]\n",
    "        file_names = sorted(os.listdir(os.path.join(data_dir, \"page\")))\n",
    "        try:\n",
    "            years = list(pd.read_csv(year_file, index_col=0)[\"0\"])\n",
    "        except:\n",
    "            years = []\n",
    "        for file_name in file_names:\n",
    "            file_counter += 1\n",
    "            if file_counter > len(years):\n",
    "                try:\n",
    "                    display(Image.open(os.path.join(data_dir, regex.sub(\".xml\", \".jpg\", file_name))))\n",
    "                except:\n",
    "                    display(Image.open(os.path.join(data_dir, regex.sub(\".xml\", \".JPG\", file_name))))\n",
    "                print(f\"data_dir: {data_dir}; file name: {file_name}; last year: {last_year};\", end=\" \")\n",
    "                print(f\"file: {file_counter}/{len(file_names)}\")\n",
    "                year = input().strip()\n",
    "                if year == \"\":\n",
    "                    year = last_year\n",
    "                years.append(year)\n",
    "                pd.DataFrame(years).to_csv(year_file)\n",
    "                last_year = year\n",
    "                clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2bcbcc-aafe-46bb-82f2-1453bfa862ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_usability(data_dirs=DATA_DIRS, usage_files=USAGE_FILES):\n",
    "    for data_dir_id in range(0, len(data_dirs)):\n",
    "        file_counter = 0\n",
    "        data_dir = data_dirs[data_dir_id]\n",
    "        usage_file = usage_files[data_dir_id]\n",
    "        file_names = sorted(os.listdir(os.path.join(data_dir, \"page\")))\n",
    "        try:\n",
    "            usage = list(pd.read_csv(usage_file, index_col=0)[\"0\"])\n",
    "        except:\n",
    "            usage = []\n",
    "        for file_name in file_names:\n",
    "            file_counter += 1\n",
    "            if file_counter > len(usage):\n",
    "                try:\n",
    "                    display(Image.open(os.path.join(data_dir, regex.sub(\".xml\", \".jpg\", file_name))))\n",
    "                except:\n",
    "                    display(Image.open(os.path.join(data_dir, regex.sub(\".xml\", \".JPG\", file_name))))\n",
    "                print(f\"data_dir: {data_dir}; file name: {file_name};\", end=\" \")\n",
    "                print(f\"file: {file_counter}/{len(file_names)}\")\n",
    "                usage_value = input().strip()\n",
    "                if usage_value == \"\":\n",
    "                    usage_value = \"yes\"\n",
    "                else:\n",
    "                    usage_value = \"no\"\n",
    "                usage.append(usage_value)\n",
    "                pd.DataFrame(usage).to_csv(usage_file)\n",
    "                clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59d0e35-755b-4334-a4de-f1fb162b0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year2decade(year):\n",
    "    return int(regex.sub(\".$\", \"\", str(year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69274431-874e-4dae-9ae7-b7b88676e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years(year_files=YEAR_FILES):\n",
    "    all_years = []\n",
    "    for file_name in year_files:\n",
    "        years = pd.read_csv(file_name, index_col=0)\n",
    "        all_years.extend(years[\"0\"])\n",
    "    return all_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557393c-579c-4028-a6c5-eeaabdf9af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decades(year_files=YEAR_FILES):\n",
    "    return [ year2decade(year) for year in get_years(year_files=YEAR_FILES) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a2c92-8fec-4f70-ae17-d9911b28fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_usage(usage_files=USAGE_FILES):\n",
    "    NBR_OF_SKIPPED_FILES = 50 # while annotation is not finished\n",
    "    usage = []\n",
    "    for file_name in usage_files:\n",
    "        usage.extend(list(pd.read_csv(file_name, index_col=0)[\"0\"]))\n",
    "    return usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a625e-f4fa-428f-9751-200a0c3d95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_file_counts(file_counts):\n",
    "    x = [ x[0] for x in list(file_counts.index) ]\n",
    "    y = list(file_counts.values)\n",
    "    plt.xticks(ticks=x, labels=[ str(x_value) + \"0\" for x_value in x ])\n",
    "    plt.title(f\"Number of scans per decade (total={sum(file_counts.values)})\")\n",
    "    plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9582a6-75b5-4ccd-8fab-dd0dee48d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_years_of_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47583933-1ecc-45ea-a5ec-6b1630495c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_file_usability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e1cdd-9e3f-47c6-a088-79c7167b72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBR_OF_SKIPPED_FILES = 50 # while annotation is not finished\n",
    "\n",
    "decades = get_decades()[:-NBR_OF_SKIPPED_FILES]\n",
    "usage = get_file_usage()[:-NBR_OF_SKIPPED_FILES]\n",
    "decades = [ decades[i] for i in range(0, len(usage)) if usage[i] == \"yes\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ef1ce-a524-449b-bc8c-9126e9b57e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_counts(pd.DataFrame(decades).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a089b1-7c15-4321-82e5-bdc9fea97b3e",
   "metadata": {},
   "source": [
    "## 2. Select complementary scans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd60aca-7332-4678-be25-8173f9f29bfd",
   "metadata": {},
   "source": [
    "Plan:\n",
    "\n",
    "1. find years\n",
    "2. remove difficult cases\n",
    "3. fill up decades to 15\n",
    "4. sort by name\n",
    "5. train layout and baseline detection\n",
    "6. train htr, check CER\n",
    "7. evaluate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd82827-a0ce-4e1e-845a-8c2b9589c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = \"../../data/Overlijden\"\n",
    "\n",
    "def random_select_scan(year):\n",
    "    year_dir = os.path.join(FILE_DIR, \"O.R. \" + str(year))\n",
    "    file_names = []\n",
    "    for region_dir in os.listdir(year_dir):\n",
    "        file_names.extend([ os.path.join(region_dir, file_name) for file_name in os.listdir(os.path.join(year_dir, region_dir)) ])\n",
    "    return file_names[random.randint(0, len(file_names) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b72f33-7697-4dc2-8bce-b499f4318fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years_from_dir(dir_name):\n",
    "    years = []\n",
    "    for file_name in os.listdir(dir_name):\n",
    "        file_name_parts = file_name.split()\n",
    "        years.append(int(file_name_parts[1]))\n",
    "    return years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c99e5c1-8b78-456a-a05b-eb88355ee5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = get_years()[:-NBR_OF_SKIPPED_FILES]\n",
    "years = [ years[i] for i in range(0, len(usage)) if usage[i] == \"yes\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad9c41-8e0d-4b49-bfeb-6cbe5b79f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DIR = os.path.join(FILE_DIR, \"x-samples\", \"complementary-2023\")\n",
    "\n",
    "target_dir_years = get_years_from_dir(TARGET_DIR)\n",
    "for decade_start in [ 1860, 1870, 1910, 1920, 1940]:\n",
    "    available_years = sorted(set([ year for year in years if year >= decade_start and year < decade_start + 10 ]))\n",
    "    for year in range(decade_start, decade_start + 10):\n",
    "        while year not in available_years and year not in target_dir_years:\n",
    "            file_name = os.path.join(FILE_DIR, \"O.R. \" + str(year), random_select_scan(year))\n",
    "            display(Image.open(file_name))\n",
    "            print(\"accept this file?\")\n",
    "            accept_value = input().strip()\n",
    "            if accept_value == \"\":\n",
    "                shutil.copy(file_name, TARGET_DIR)\n",
    "                available_years.append(year)\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40545a9-5129-4a11-94a0-e887581087a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_select_scan(1871)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b21f8-4edc-45f8-824e-63da39bcfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text, meta_data, file_regions = get_text_from_file(os.path.join(DATA_DIRS[0], \"page\", \"p001.xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce026b7b-bc36-41a7-8f34-9dad6fce49c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "saw_trigger_word = False\n",
    "for line in  text.split(\"\\n\"):\n",
    "    if saw_trigger_word:\n",
    "        print(line)\n",
    "        break\n",
    "    if regex.search(\"^Heden\", line):\n",
    "        saw_trigger_word = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6636b7f1-f520-4abc-8253-d72e98e70d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
