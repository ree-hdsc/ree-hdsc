{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e2bc757-f218-4c26-b6c6-2454b8dc007b",
   "metadata": {},
   "source": [
    "# Explore manually annotated Cura√ßao files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0e29a-453f-4a4e-9171-e554d72128e3",
   "metadata": {},
   "source": [
    "## 1. Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f712aeb-f9cd-4776-8985-d7ad699d7e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import re\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6753339-cc90-42c7-a7c5-7d64dd8d53ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data/Training_set_V2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9148d-d272-40b2-8612-23c3b7610c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_from_file(file_name):\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "    return get_text_from_xml(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542a5e2-6db4-4c4b-9b12-80c4a4368506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_from_xml(root):\n",
    "    text = \"\"\n",
    "    for textline in root.findall(\".//{*}TextLine\"):\n",
    "        custom_dict = make_custom_dict(textline.attrib)\n",
    "        for unicode in textline.findall(\"./{*}TextEquiv/{*}Unicode\"):\n",
    "            text += remove_strikethroughs(unicode.text, custom_dict) + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74eb62-a95c-441c-b3cd-f8202ed6df8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_custom_dict(text_line_attributes):\n",
    "    if \"custom\" not in text_line_attributes:\n",
    "        return {}\n",
    "    custom_tokens = text_line_attributes[\"custom\"].split()\n",
    "    custom_dict = {}\n",
    "    while custom_tokens:\n",
    "        custom_key = custom_tokens.pop(0)\n",
    "        custom_value = custom_tokens.pop(0)\n",
    "        while custom_tokens and not re.search(\"}$\", custom_value):\n",
    "            custom_value += \" \" + custom_tokens.pop(0)\n",
    "        if custom_key in custom_dict:\n",
    "            custom_dict[custom_key].append(ast.literal_eval(json_string_add_quotes(custom_value)))\n",
    "        else:\n",
    "            custom_dict[custom_key] = [ast.literal_eval(json_string_add_quotes(custom_value))]\n",
    "    return custom_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f21338-20d2-4f83-a4e7-66a48fd1d772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_strikethroughs(text_line, custom_dict):\n",
    "    if \"textStyle\" not in custom_dict:\n",
    "        return text_line\n",
    "    chars = list(text_line)\n",
    "    for strikethrough in custom_dict[\"textStyle\"]:\n",
    "        if \"strikethrough\" in strikethrough:\n",
    "            start = int(strikethrough[\"offset\"])\n",
    "            for i in range(start, start + int(strikethrough[\"length\"])):\n",
    "                chars[i] = \" \"\n",
    "    return \"\".join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a307ac6-4f4c-4f1a-82ba-f01498516d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def json_string_add_quotes(string):\n",
    "    return re.sub(\"{ *\", \"{ '\", \n",
    "               re.sub(\": *\", \"': '\", \n",
    "                   re.sub(\"; *\", \"', '\",\n",
    "                       re.sub(\"} *'\", \"} \",\n",
    "                           re.sub(\"; *}\", \"' }\", string)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb7abc-b1bb-48d6-9719-33b52723d81c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_file_name(file_id):\n",
    "    return \"p\" + str(file_id).zfill(3) + \".xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a43456-ec67-4c0e-99d0-2a4a34c945fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_files():\n",
    "    texts = {}\n",
    "    for file_id in range(1, 100):\n",
    "        try:\n",
    "            texts[file_id] = get_text_from_file(data_dir + \"/\" + make_file_name(file_id))\n",
    "        except:\n",
    "            pass\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962bd915-fe8d-4fc0-835c-69ad9bd09e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = read_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f2ef2-d628-4876-bfd1-ded589cc8fac",
   "metadata": {},
   "source": [
    "## 2. Find entities in texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb715fe-d3af-49e7-a296-cd2121027068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a58dd-4ff9-4295-9441-de917473ef4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_names(entities):\n",
    "    name = \"\"\n",
    "    for part in entities:\n",
    "        if re.search(\"^B\", part[\"entity\"]) and name != \"\":\n",
    "            print(name)\n",
    "            name = \"\"\n",
    "        if re.search(\"(GPE|PERSON)$\", part[\"entity\"]):\n",
    "            if name != \"\":\n",
    "                name += \" \"\n",
    "            name += part[\"word\"]\n",
    "    if name != \"\":\n",
    "        print(name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50688d0-2fed-43f5-a5ad-1828a3e45c6b",
   "metadata": {},
   "source": [
    "Tested models (initial number indicates monthly downloads):\n",
    "* (345) wietsedv/bert-base-dutch-cased-finetuned-conll2002-ner (several false positives)\n",
    "* (74) Matthijsvanhof/bert-base-dutch-cased-finetuned-NER (not useful, tags everything)\n",
    "* (16) wietsedv/bert-base-dutch-cased-finetuned-sonar-ner (some false positives)\n",
    "* (13) proycon/bert-ner-cased-conll2002-nld (did not find any entities)\n",
    "* (10) proycon/bert-ner-cased-sonar1-nld (found only one entity)\n",
    "* (10) Matthijsvanhof/bert-base-dutch-cased-finetuned-NER8 (not useful, tags everything)\n",
    "* (4) [wietsedv/bert-base-dutch-cased-finetuned-udlassy-ner](https://huggingface.co/wietsedv/bert-base-dutch-cased-finetuned-udlassy-ner) (few false positives) **SELECTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0ba95-6d64-401b-aebb-b49a23874413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_bert_pipeline = transformers.pipeline(task='ner', model='wietsedv/bert-base-dutch-cased-finetuned-udlassy-ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d26c1-b6a9-4b0a-a48b-a3cd743b7f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entities = run_bert_pipeline(texts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1c588-1596-457f-8149-c821fbe94f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_names(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603d2cf-c1db-4406-b378-c08e8837712d",
   "metadata": {},
   "source": [
    "## 3. Visualize entities\n",
    "\n",
    "For list of entity tags of model `wietsedv/bert-base-dutch-cased-finetuned-udlassy-ner`, see [OntoNotes](https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf), page 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115f52c-a345-4bf5-ac6f-0bd4cb3a9924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35af923-180b-4b4a-b4f1-912cc682017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_entities(entities_in):\n",
    "    entities_out = []\n",
    "    for entity in entities_in:\n",
    "        start_tag = entity[\"entity\"][0]\n",
    "        label = entity[\"entity\"][2:]\n",
    "        if start_tag == \"B\" or not entities_out:\n",
    "            entities_out.append({\"start\": entity[\"start\"], \"end\": entity[\"end\"], \"label\": label})\n",
    "        else:\n",
    "            entities_out[-1][\"end\"] = entity[\"end\"]\n",
    "    return entities_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56502de2-83fd-4a6a-b200-74449bbea1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def render_text(text, entities):\n",
    "    displacy.render({ \"text\": re.sub(\"\\\\n\", \" \", text), \n",
    "                      \"ents\": convert_entities(entities) }, \n",
    "                      options = { \"colors\": { \"PERSON\": \"orange\" } }, style = \"ent\", manual = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53782c7c-79d2-4b84-b85e-8a742e954da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "render_text(texts[2], entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5764092-bb7a-4205-aff1-e0f60750c294",
   "metadata": {},
   "source": [
    "## 4. Post-process entities\n",
    "\n",
    "Expand entities which end in the middle of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408c464-2237-45be-adb0-b91b58c4705d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_entities(entities_in, text):\n",
    "    entities_out = []\n",
    "    for entity_in in entities_in:\n",
    "        entity_out = entity_in.copy()\n",
    "        while (entity_out[\"end\"] < len(text) and \n",
    "               (re.search(\"\\w\", text[entity_out[\"end\"]]) or re.search(\"[.,-]\", text[entity_out[\"end\"]]))):\n",
    "            entity_out[\"word\"] += text[entity_out['end']]\n",
    "            entity_out[\"end\"] += 1\n",
    "        entities_out.append(entity_out)\n",
    "    return entities_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a5f39-1112-4fc2-aee3-171a0aae31fb",
   "metadata": {},
   "source": [
    "Combine successive entities where the second one has a label starting with I or the same label as the previous entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519aa385-eebf-4c80-b7e8-574546acaec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_entities(entities_in):\n",
    "    entities_out = []\n",
    "    for entity_in in entities_in:\n",
    "        entity_out = entity_in.copy()\n",
    "        if len(entities_out) == 0:\n",
    "            entities_out.append(entity_out)\n",
    "        elif re.search(\"^I-\", entity_out[\"entity\"]):\n",
    "            expand_last_entity(entities_out, entity_out)\n",
    "        else:\n",
    "            entity_out[\"entity\"] = re.sub(\"^[BIE]-\", \"B-\", entity_out[\"entity\"])\n",
    "            if entity_out[\"start\"] < entities_out[-1][\"start\"]:\n",
    "                print(\"error: entities are not sorted by position!\")\n",
    "            elif entity_out[\"start\"] <= entities_out[-1][\"end\"] + 1 and entity_out[\"entity\"] == entities_out[-1][\"entity\"]:\n",
    "                expand_last_entity(entities_out, entity_out)\n",
    "            else:\n",
    "                entities_out.append(entity_out)\n",
    "    return entities_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31be041-f952-4905-aa32-50e67714770b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_last_entity(entities, entity):\n",
    "    entities[-1][\"word\"] += \" \" + entity[\"word\"]\n",
    "    entities[-1][\"end\"] = entity[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6236c-3652-427c-a762-05bb5d1c606f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entities = run_bert_pipeline(texts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3a11d-4a90-4dda-a35a-0c0df11f620e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entities = combine_entities(expand_entities(entities, texts[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058c12e-2594-4b7f-b62c-b43e59e36d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "render_text(texts[2], entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d9944-7f04-4719-bb02-2d326467ad00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_and_render_texts(texts):\n",
    "    for text_id in texts:\n",
    "        text = texts[text_id]\n",
    "        entities = run_bert_pipeline(text)\n",
    "        entities = combine_entities(expand_entities(entities, text))\n",
    "        print(f\"Text {text_id}\")\n",
    "        render_text(text, entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4704120-01b7-44b5-ac6c-710a789c7efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_and_render_texts({ text_id:texts[text_id] for text_id in texts if text_id < 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fccebfa-cd62-43a1-a6ad-5f4b1dc0602e",
   "metadata": {},
   "source": [
    "## 5. Get name of deceased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9bef6-836d-49cc-92be-b26317f921fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_text_patterns(query, text):\n",
    "    positions = []\n",
    "    pattern = re.compile(query)\n",
    "    for m in pattern.finditer(text):\n",
    "        positions.append({\"start\": m.start(), \"end\": m.end()})\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681fc8f-1c54-4aa1-bd2e-e5ff73858150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_name_of_deceased(text, entities):\n",
    "    deceased = []\n",
    "    positions = find_text_patterns(\"overleden is:?,?\", text) \n",
    "    for position in positions:\n",
    "        name_deceased = \"\"\n",
    "        for entity in entities:\n",
    "            if entity[\"start\"] == position[\"end\"] + 1:\n",
    "                name_deceased = entity[\"word\"]\n",
    "        deceased.append(name_deceased)\n",
    "    positions = find_text_patterns(\"levens?loos\", text)\n",
    "    return deceased, len(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec810024-dc96-43d2-b0e9-229818c63a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for text_id in texts:\n",
    "    text = texts[text_id]\n",
    "    entities = run_bert_pipeline(text)\n",
    "    entities = combine_entities(expand_entities(entities, text))\n",
    "    print(f\"Text {text_id}:\", end=\" \")\n",
    "    print(get_name_of_deceased(text, entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d1012f-2345-4f77-bfae-4a31c05495bc",
   "metadata": {},
   "source": [
    "## 6. Get decease date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b20a3-953c-49f6-bde5-e5331d35a85d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_days = { '': 0, \"eersten\": 1, \"tweeden\": 2, \"derden\": 3, \"vierden\": 4, \"vijfden\": 5,\n",
    "              \"zesden\": 6, \"zevenden\": 7, \"achtsten\": 8, \"negenden\": 9, \"tienden\": 10,\n",
    "              \"elfden\": 11, \"twaalfden\": 12, \"dertienden\": 13, \"veertienden\": 14, \"vijftienden\": 15,\n",
    "              \"zestienden\": 16, \"zeventienden\": 17, \"achttienden\": 18, \"negentienden\": 19, \"twintigsten\": 20,\n",
    "              \"eenentwintigsten\": 21, \"tweeentwintigsten\": 22, \"drieentwintigsten\": 23, \"vierentwintigsten\": 24, \"vijfentwintigsten\": 25,\n",
    "              \"zesentwintigsten\": 26, \"zevenentwintigsten\": 27, \"achtentwintigsten\": 28, \"negenentwintigsten\": 29, \"dertigsten\": 30,\n",
    "              \"eenendertigsten\": 31,\n",
    "              \"eerste\": 1, \"tweede\": 2, \"derde\": 3, \"vierde\": 4, \"vijfde\": 5,\n",
    "              \"zesde\": 6, \"zevende\": 7, \"achtste\": 8, \"negende\": 9, \"tiende\": 10,\n",
    "              \"elfde\": 11, \"twaalfde\": 12, \"dertiende\": 13, \"veertiende\": 14, \"vijftiende\": 15,\n",
    "              \"zestiende\": 16, \"zeventiende\": 17, \"achttiende\": 18, \"negentiende\": 19, \"twintigste\": 20,\n",
    "              \"eenentwintigste\": 21, \"tweeentwintigste\": 22, \"drieentwintigste\": 23, \"vierentwintigste\": 24, \"vijfentwintigste\": 25,\n",
    "              \"zesentwintigste\": 26, \"zevenentwintigste\": 27, \"achtentwintigste\": 28, \"negenentwintigste\": 29, \"dertigste\": 30,\n",
    "              \"eenendertigste\": 31,\n",
    "              \"een en twintigsten\": 21, \"twee en twintigsten\": 22, \"drie en twintigsten\": 23, \"vier en twintigsten\": 24, \"vijf en twintigsten\": 25,\n",
    "              \"zes en twintigsten\": 26, \"zeven en twintigsten\": 27, \"acht en twintigsten\": 28, \"negen en twintigsten\": 29, \n",
    "              \"een en dertigsten\": 31,\n",
    "              \"een en twintigste\": 21, \"twee en twintigste\": 22, \"drie en twintigste\": 23, \"vier en twintigste\": 24, \"vijf en twintigste\": 25,\n",
    "              \"zes en twintigste\": 26, \"zeven en twintigste\": 27, \"acht en twintigste\": 28, \"negen en twintigste\": 29, \n",
    "              \"een en dertigste\": 31,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce63903-b191-4283-9ea9-9b00625cc2d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_months = { '': 0, \"januari\": 1, \"februari\": 2, \"maart\": 3, \"april\": 4, \"mei\": 5, \"juni\": 6,\n",
    "                \"juli\": 7, \"augustus\": 8, \"september\": 9, \"oktober\": 10, \"november\": 11, \"december\": 12,\n",
    "                \"july\": 7, \"october\": 10, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a480b-34b2-45d5-bb2a-9e5fcbb73acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_next_token(position, text):\n",
    "    while position < len(text) - 1 and re.search(\"\\s\", text[position]):\n",
    "        position += 1\n",
    "    token = \"\"\n",
    "    while position < len(text) - 1 and not re.search(\"\\s\", text[position]):\n",
    "        token += text[position]\n",
    "        position += 1\n",
    "    return token, position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9203f949-eaf7-4678-96a5-810562e83d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup(token):\n",
    "    return re.sub(\"\\W?$\", \"\", token.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2077510-eb9e-44c9-8767-970427f16826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_date_day(position, text):\n",
    "    day = \"\"\n",
    "    next_token, end_position = get_next_token(position, text)\n",
    "    if cleanup(next_token) in date_days.keys():\n",
    "        day = next_token\n",
    "    else:\n",
    "        next_next_token, end_position = get_next_token(position + len(next_token) + 1, text)\n",
    "        next_token += \" \" + next_next_token\n",
    "        if cleanup(next_token) in date_days.keys():\n",
    "            day = next_token\n",
    "        else:\n",
    "            next_next_token, end_position = get_next_token(position + len(next_token) + 1, text)\n",
    "            next_token += \" \" + next_next_token\n",
    "            if cleanup(next_token) in date_days.keys():\n",
    "                day = next_token\n",
    "    if day:\n",
    "        return day, end_position - position\n",
    "    else:\n",
    "        return day, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e9111-45d2-49e0-ab88-803a79672463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_date_month(position, text):\n",
    "    month = \"\"\n",
    "    next_token, end_position = get_next_token(position, text)\n",
    "    if cleanup(next_token) in date_months.keys():\n",
    "        month = next_token\n",
    "    elif re.search(\"-$\", next_token):\n",
    "        next_next_token, next_end_position = get_next_token(end_position, text)\n",
    "        next_token = re.sub(\"-$\", \"\", next_token)\n",
    "        next_token += next_next_token\n",
    "        if cleanup(next_token) in date_months.keys():\n",
    "            month = next_token\n",
    "            end_position = next_end_position\n",
    "    if month:\n",
    "        return month, end_position - position\n",
    "    else:\n",
    "        return month, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f4f9be-d3c3-4a05-bcee-25ad235eb289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_date_year(position, text):\n",
    "    year = \"\"\n",
    "    next_token, next_position = get_next_token(position, text)\n",
    "    next_token, next_position = get_next_token(next_position, text)\n",
    "    next_token, next_position = get_next_token(next_position, text)\n",
    "    if cleanup(next_token) == \"een\":\n",
    "        year = next_token\n",
    "        next_token, next_position = get_next_token(next_position, text)\n",
    "        if cleanup(next_token) == \"duizend\":\n",
    "            year += \" \" + next_token\n",
    "            finished = False\n",
    "            while not finished:\n",
    "                next_token, next_position = get_next_token(next_position, text)\n",
    "                if next_token != \"te\":\n",
    "                    year += \" \" + next_token\n",
    "                finished = next_token == \"te\" or re.search(\",$\", next_token)\n",
    "            next_token, next_position = get_next_token(next_position, text)\n",
    "    return year, next_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca86f2-f4f4-4ecf-86d1-9b4e9b117477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "digits = { \"een\": 1, \"twee\": 2, \"drie\": 3, \"vier\": 4, \"vijf\": 5, \"zes\": 6, \"zeven\": 7, \"acht\": 8, \"negen\": 9 }\n",
    "decades = { \"tien\": 10, \"twintig\": 20, \"dertig\": 30, \"veertig\": 40, \"vijftig\": 50, \"zestig\": 60, \"zeventig\": 70, \"tachtig\": 80, \"negentig\": 90 } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da031d75-1f94-41d7-9d0c-da8b530a7916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def number_parser(text, number):\n",
    "    if not text:\n",
    "        return 0\n",
    "    tokens = text.split()\n",
    "    if len(tokens) > 1 and cleanup(tokens[0]) == \"een\" and cleanup(tokens[1]) == \"duizend\":\n",
    "        return 1000 + number_parser(\" \".join(tokens[2:]), number)\n",
    "    if cleanup(tokens[0]) == \"en\":\n",
    "        return number_parser(\" \".join(tokens[1:]), number)\n",
    "    if cleanup(tokens[0]) in digits:\n",
    "        if len(tokens) > 1 and cleanup(tokens[1]) == \"honderd\":\n",
    "            return 100 * digits[cleanup(tokens[0])] + number_parser(\" \".join(tokens[2:]), number)\n",
    "        return digits[cleanup(tokens[0])] + number_parser(\" \".join(tokens[1:]), number)\n",
    "    if cleanup(tokens[0]) in decades:\n",
    "        return decades[cleanup(tokens[0])] + number_parser(\" \".join(tokens[1:]), number)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fabc58-a443-46a4-92d3-8f906bb42fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for text_id in texts:\n",
    "    text = texts[text_id]\n",
    "    entities = run_bert_pipeline(text)\n",
    "    entities = combine_entities(expand_entities(entities, text))\n",
    "    day = \"\"\n",
    "    for position in find_text_patterns(\"op den\", text):\n",
    "        day, token_length_day = get_date_day(position[\"end\"], text)\n",
    "        month, token_length_month = get_date_month(position[\"end\"] + token_length_day, text)\n",
    "        year, token_length_year = get_date_year(position[\"end\"] + token_length_day + token_length_month, text)\n",
    "        year = re.sub(\" *honderd\", \" honderd\", year)\n",
    "        try:\n",
    "            print(f\"Text {text_id}: {day} {month} {year} ({date_days[cleanup(day)]}-{date_months[cleanup(month)]}-{number_parser(year, 0)})\")\n",
    "        except:\n",
    "            print(f\"Text {text_id}: {day} {month} {year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d69ef7-5374-4241-bd7f-f6e4f758abdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
