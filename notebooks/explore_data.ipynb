{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e2bc757-f218-4c26-b6c6-2454b8dc007b",
   "metadata": {},
   "source": [
    "# Explore manually annotated Cura√ßao files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0e29a-453f-4a4e-9171-e554d72128e3",
   "metadata": {},
   "source": [
    "## 1. Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f712aeb-f9cd-4776-8985-d7ad699d7e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "from scripts import read_transkribus_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff98c4ed-69d9-4937-8e0a-9052694b2f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_with_color(string, color_code=1):\n",
    "    print(f\"\\x1b[3{color_code}m{string}\\x1b[m\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962bd915-fe8d-4fc0-835c-69ad9bd09e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_dir = \"../../data/Training_set_V2/\"\n",
    "#data_dir = \"../../data/Sample_regex/Sample_regex/page/\"\n",
    "#data_dir = \"../../data/Overlijden/x-samples/first-38/page\"\n",
    "data_dir = \"../../data/Overlijden/x-samples/three-columns-100/page\"\n",
    "\n",
    "texts, metadata, textregions = read_transkribus_files.read_files(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603d2cf-c1db-4406-b378-c08e8837712d",
   "metadata": {},
   "source": [
    "## 2. Visualize entities\n",
    "\n",
    "For list of entity tags of model `wietsedv/bert-base-dutch-cased-finetuned-udlassy-ner`, see [OntoNotes](https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf), page 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115f52c-a345-4bf5-ac6f-0bd4cb3a9924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56502de2-83fd-4a6a-b200-74449bbea1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def render_text(text, entities):\n",
    "    displacy.render({ \"text\": re.sub(\"\\\\n\", \" \", text), \n",
    "                      \"ents\": entities }, \n",
    "                      options = { \"colors\": { \"PERSON\": \"orange\", \n",
    "                                              \"first_names\": \"orange\", \n",
    "                                              \"last_name\": \"orange\" } }, style = \"ent\", manual = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35af923-180b-4b4a-b4f1-912cc682017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_guessed_entities(entities_in):\n",
    "    entities_out = []\n",
    "    for entity in entities_in:\n",
    "        start_tag = entity[\"entity\"][0]\n",
    "        label = entity[\"entity\"][2:]\n",
    "        if start_tag == \"B\" or not entities_out:\n",
    "            entities_out.append({\"start\": entity[\"start\"], \"end\": entity[\"end\"], \"label\": label})\n",
    "        else:\n",
    "            entities_out[-1][\"end\"] = entity[\"end\"]\n",
    "    return entities_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30879ef9-3558-406e-bec6-0d9855d7ef5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def continued_entity(entity, last_entity):\n",
    "    return(\"continued\" in entity.keys() and \n",
    "           \"continued\" in last_entity.keys() and \n",
    "           int(entity[\"offset\"]) == int(last_entity[\"offset\"]) + int(last_entity[\"length\"]) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d44fb9-4800-45bf-994d-5a5ed9936e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_gold_entities(entities_in):\n",
    "    entities_out = []\n",
    "    for key in entities_in:\n",
    "        if \"offset\" in entities_in[key][0]:\n",
    "            last_entity = {}\n",
    "            for entity in entities_in[key]:\n",
    "                if continued_entity(entity, last_entity):\n",
    "                    entities_out[-1][\"end\"] = int(entity[\"offset\"]) + int(entity[\"length\"])\n",
    "                else:\n",
    "                    entities_out.append({\"start\": int(entity[\"offset\"]), \n",
    "                                         \"end\": int(entity[\"offset\"]) + int(entity[\"length\"]),\n",
    "                                         \"label\": key})\n",
    "                last_entity = entity.copy()\n",
    "    return entities_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf135d5-32b9-467a-bf9c-b024d536f3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ignore_entities(entities_in, labels_to_omit):\n",
    "    entities_out = []\n",
    "    for entity in entities_in:\n",
    "        if entity[\"label\"] not in labels_to_omit:\n",
    "            entities_out.append(entity)\n",
    "    return entities_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf201ce5-d94f-4213-a51b-50290b06478c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_key = 1831001\n",
    "render_text(texts[test_key], ignore_entities(convert_gold_entities(metadata[test_key]), [\"textStyle\", \"unclear\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f2ef2-d628-4876-bfd1-ded589cc8fac",
   "metadata": {},
   "source": [
    "## 3. Find entities in texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb715fe-d3af-49e7-a296-cd2121027068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a58dd-4ff9-4295-9441-de917473ef4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_names(entities):\n",
    "    name = \"\"\n",
    "    for part in entities:\n",
    "        if re.search(\"^B\", part[\"entity\"]) and name != \"\":\n",
    "            print(name)\n",
    "            name = \"\"\n",
    "        if re.search(\"(GPE|PERSON)$\", part[\"entity\"]):\n",
    "            if name != \"\":\n",
    "                name += \" \"\n",
    "            name += part[\"word\"]\n",
    "    if name != \"\":\n",
    "        print(name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50688d0-2fed-43f5-a5ad-1828a3e45c6b",
   "metadata": {},
   "source": [
    "Tested models (initial number indicates monthly downloads):\n",
    "* (345) wietsedv/bert-base-dutch-cased-finetuned-conll2002-ner (several false positives)\n",
    "* (74) Matthijsvanhof/bert-base-dutch-cased-finetuned-NER (not useful, tags everything)\n",
    "* (16) wietsedv/bert-base-dutch-cased-finetuned-sonar-ner (some false positives)\n",
    "* (13) proycon/bert-ner-cased-conll2002-nld (did not find any entities)\n",
    "* (10) proycon/bert-ner-cased-sonar1-nld (found only one entity)\n",
    "* (10) Matthijsvanhof/bert-base-dutch-cased-finetuned-NER8 (not useful, tags everything)\n",
    "* (4) [wietsedv/bert-base-dutch-cased-finetuned-udlassy-ner](https://huggingface.co/wietsedv/bert-base-dutch-cased-finetuned-udlassy-ner) (few false positives) **SELECTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0ba95-6d64-401b-aebb-b49a23874413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_bert_pipeline = transformers.pipeline(task='ner', model='wietsedv/bert-base-dutch-cased-finetuned-udlassy-ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d26c1-b6a9-4b0a-a48b-a3cd743b7f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entities = run_bert_pipeline(texts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1c588-1596-457f-8149-c821fbe94f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_names(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5764092-bb7a-4205-aff1-e0f60750c294",
   "metadata": {},
   "source": [
    "## 4. Post-process entities\n",
    "\n",
    "Expand entities which end in the middle of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408c464-2237-45be-adb0-b91b58c4705d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_entities(entities_in, text):\n",
    "    entities_out = []\n",
    "    for entity_in in entities_in:\n",
    "        entity_out = entity_in.copy()\n",
    "        while (entity_out[\"end\"] < len(text) and \n",
    "               (re.search(\"\\w\", text[entity_out[\"end\"]]) or re.search(\"[.,-]\", text[entity_out[\"end\"]]))):\n",
    "            entity_out[\"word\"] += text[entity_out['end']]\n",
    "            entity_out[\"end\"] += 1\n",
    "        entities_out.append(entity_out)\n",
    "    return entities_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a5f39-1112-4fc2-aee3-171a0aae31fb",
   "metadata": {},
   "source": [
    "Combine successive entities where the second one has a label starting with I or the same label as the previous entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31be041-f952-4905-aa32-50e67714770b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_last_entity(entities, entity):\n",
    "    entities[-1][\"word\"] += \" \" + entity[\"word\"]\n",
    "    entities[-1][\"end\"] = entity[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519aa385-eebf-4c80-b7e8-574546acaec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_entities(entities_in):\n",
    "    entities_out = []\n",
    "    for entity_in in entities_in:\n",
    "        entity_out = entity_in.copy()\n",
    "        if len(entities_out) == 0:\n",
    "            entities_out.append(entity_out)\n",
    "        elif re.search(\"^I-\", entity_out[\"entity\"]):\n",
    "            expand_last_entity(entities_out, entity_out)\n",
    "        else:\n",
    "            entity_out[\"entity\"] = re.sub(\"^[BIE]-\", \"B-\", entity_out[\"entity\"])\n",
    "            if entity_out[\"start\"] < entities_out[-1][\"start\"]:\n",
    "                print(\"error: entities are not sorted by position!\")\n",
    "            elif entity_out[\"start\"] <= entities_out[-1][\"end\"] + 1 and entity_out[\"entity\"] == entities_out[-1][\"entity\"]:\n",
    "                expand_last_entity(entities_out, entity_out)\n",
    "            else:\n",
    "                entities_out.append(entity_out)\n",
    "    return entities_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d9944-7f04-4719-bb02-2d326467ad00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_and_render_texts(texts):\n",
    "    for text_id in texts:\n",
    "        text = texts[text_id]\n",
    "        entities = run_bert_pipeline(text)\n",
    "        entities = combine_entities(expand_entities(entities, text))\n",
    "        print(f\"Text {text_id}\")\n",
    "        render_text(text, convert_guessed_entities(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4704120-01b7-44b5-ac6c-710a789c7efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_and_render_texts({ text_id:texts[text_id] for text_id in texts if text_id < 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fccebfa-cd62-43a1-a6ad-5f4b1dc0602e",
   "metadata": {},
   "source": [
    "## 5. Get name of deceased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9203f949-eaf7-4678-96a5-810562e83d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup(text_in):\n",
    "    text_out = re.sub(\"\\s+\", \" \", text_in)\n",
    "    text_out = re.sub(\"- \", \"\", text_out)\n",
    "    return re.sub(\"[,.]\", \"\", text_out.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9bef6-836d-49cc-92be-b26317f921fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_text_patterns(query, text):\n",
    "    positions = []\n",
    "    pattern = re.compile(query)\n",
    "    for m in pattern.finditer(text.lower()):\n",
    "        positions.append({\"start\": m.start(), \"end\": m.end()})\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681fc8f-1c54-4aa1-bd2e-e5ff73858150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_name_of_deceased(text, entities):\n",
    "    deceased = []\n",
    "    positions = find_text_patterns(\"overleden is:?,?\", text) + find_text_patterns(\"is overleden:?,?\", text)\n",
    "    for position in positions:\n",
    "        name_deceased = \"\"\n",
    "        for entity in entities:\n",
    "            if entity[\"start\"] == position[\"end\"] + 1:\n",
    "                name_deceased = entity[\"word\"]\n",
    "        deceased.append(name_deceased)\n",
    "    positions = find_text_patterns(\"levens?loos\", text)\n",
    "    return deceased, len(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52887b2d-7052-498a-9e28-80f342055340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_names(results, metadata):\n",
    "    if len(results[0]) == 0 or results[0][0] == \"\":\n",
    "        return True\n",
    "    if \"first_names\" not in metadata or \"last_name\" not in metadata:\n",
    "        return(False)\n",
    "    guessed_name = results[0][0]\n",
    "    if re.search(\".,.\", guessed_name):\n",
    "        guessed_name = re.sub(\"^[^,]+, *(\\S.*)$\", \"\\\\1\", results[0][0]) + \" \" + re.sub(\"^([^,]+),.*$\", \"\\\\1\", results[0][0])\n",
    "    annotated_name = \" \".join([ metadata[\"first_names\"], metadata[\"last_name\"]])\n",
    "    return cleanup(guessed_name) == cleanup(annotated_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09f21e-4bc3-4fe9-aa5b-cec1355a0d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_deceased_names(results, nbr_of_names_found, nbr_of_stillborns_found, metadata):\n",
    "    if len(results[0]) != 0 and re.search(\"\\w\", results[0][0]):\n",
    "        nbr_of_names_found += 1\n",
    "    if results[1] > 0:\n",
    "        nbr_of_stillborns_found += 1\n",
    "    return nbr_of_names_found, nbr_of_stillborns_found, compare_names(results, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f9bf8-e797-4637-bb66-906cd06ead9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metadata(metadata, text, keys):\n",
    "    data = {}\n",
    "    for key in keys:\n",
    "        if key in metadata:\n",
    "            for metadata_item in metadata[key]:\n",
    "                name = text[int(metadata_item[\"offset\"]): \n",
    "                            int(metadata_item[\"offset\"]) + int(metadata_item[\"length\"])]\n",
    "                if key not in data:\n",
    "                    data[key] = name\n",
    "                else:\n",
    "                    data[key] += \" \" + name\n",
    "    return data               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ff1e2-ce54-4d9f-abc3-e437ac327fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_name_correct(name_is_correct):\n",
    "    if not name_is_correct:\n",
    "        print_with_color(\"wrong name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489cf73b-588e-46d0-8b03-155fd79bcc90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GOLD_DATA = \"../../data/Overlijden/x-samples/three-columns-100.csv\"\n",
    "gold_data = pd.read_csv(GOLD_DATA)\n",
    "names = {}\n",
    "for key in gold_data.index:\n",
    "    names_key = read_transkribus_files.make_file_id(gold_data[\"scans\"][key])\n",
    "    if isinstance(gold_data[\"first_names\"][key], str):\n",
    "        if isinstance(gold_data[\"last_name\"][key], str):\n",
    "            name = str(gold_data[\"first_names\"][key]) + \" \" + str(gold_data[\"last_name\"][key])\n",
    "        else:\n",
    "            name = str(gold_data[\"first_names\"][key])\n",
    "    elif isinstance(gold_data[\"last_name\"][key], str):\n",
    "        name = str(gold_data[\"last_name\"][key])\n",
    "    if names_key in names:\n",
    "        names[names_key].append(name)\n",
    "    else:\n",
    "        names[names_key] = [name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec810024-dc96-43d2-b0e9-229818c63a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nbr_of_names_found = 0\n",
    "nbr_of_stillborns_found = 0\n",
    "\n",
    "for text_id in sorted(texts.keys()):\n",
    "    text = texts[text_id]\n",
    "    entities = run_bert_pipeline(text)\n",
    "    entities = combine_entities(expand_entities(entities, text))\n",
    "    #print(f\"Text {text_id}:\", end=\" \")\n",
    "    results = get_name_of_deceased(text, entities)\n",
    "    nbr_of_names_found, nbr_of_stillborns_found, name_is_correct = evaluate_deceased_names(results, \n",
    "                                                                          nbr_of_names_found, \n",
    "                                                                          nbr_of_stillborns_found,\n",
    "                        get_metadata(metadata[text_id], texts[text_id], [\"first_names\", \"last_name\"]))\n",
    "    #print(results, end=\" \")\n",
    "    #print_name_correct(name_is_correct)\n",
    "    #print()\n",
    "    print(results[0][0].lower() == names[text_id][0].lower(), text_id, results[0][0], names[text_id][0])\n",
    "print(f\"Records: {len(texts)}; Names found: {nbr_of_names_found};\", end=\" \")\n",
    "print(f\"Stillborns: {nbr_of_stillborns_found}; Missing: {len(texts)-nbr_of_names_found-nbr_of_stillborns_found}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d1012f-2345-4f77-bfae-4a31c05495bc",
   "metadata": {},
   "source": [
    "## 6. Get decease date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bb60e-0c61-4ea3-9fb4-f8439a370fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b20a3-953c-49f6-bde5-e5331d35a85d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordinals = { \"eersten\": 1, \"tweeden\": 2, \"derden\": 3, \"vierden\": 4, \"vijfden\": 5,\n",
    "             \"zesden\": 6, \"zevenden\": 7, \"achtsten\": 8, \"negenden\": 9, \"tienden\": 10,\n",
    "             \"elfden\": 11, \"twaalfden\": 12, \"dertienden\": 13, \"veertienden\": 14, \"vijftienden\": 15,\n",
    "             \"zestienden\": 16, \"zeventienden\": 17, \"achttienden\": 18, \"negentienden\": 19, \"twintigsten\": 20,\n",
    "             \"eenentwintigsten\": 21, \"tweeentwintigsten\": 22, \"drieentwintigsten\": 23, \"vierentwintigsten\": 24, \"vijfentwintigsten\": 25,\n",
    "             \"zesentwintigsten\": 26, \"zevenentwintigsten\": 27, \"achtentwintigsten\": 28, \"negenentwintigsten\": 29, \"dertigsten\": 30,\n",
    "             \"eenendertigsten\": 31,\n",
    "             \"een en twintigsten\": 21, \"twee en twintigsten\": 22, \"drie en twintigsten\": 23, \"vier en twintigsten\": 24, \"vijf en twintigsten\": 25,\n",
    "             \"zes en twintigsten\": 26, \"zeven en twintigsten\": 27, \"acht en twintigsten\": 28, \"negen en twintigsten\": 29, \n",
    "             \"een en dertigsten\": 31,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca86f2-f4f4-4ecf-86d1-9b4e9b117477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cardinals = {             \"een\": 1,  \"twee\": 2,     \"drie\": 3,     \"vier\": 4,      \"vijf\": 5,      \"zes\": 6,      \"zeven\": 7,      \"acht\": 8,     \"negen\": 9,\n",
    "              \"tien\": 10, \"elf\": 11, \"twaalf\": 12,  \"dertien\": 13, \"veertien\": 14, \"vijftien\": 15, \"zestien\": 16, \"zeventien\": 17, \"achttien\":18, \"negentien\": 19,\n",
    "                                     \"twintig\": 20, \"dertig\": 30,  \"veertig\": 40,  \"vijftig\": 50,  \"zestig\": 60,  \"zeventig\": 70,  \"tachtig\": 80, \"negentig\": 90, } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2bd2c-2554-4942-ae67-5f065c121891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "others = { \"en\": 0, \"honderd\": 100, \"duizend\": 1000, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce63903-b191-4283-9ea9-9b00625cc2d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_months = { '': 0, \"januari\": 1, \"februari\": 2, \"maart\": 3, \"april\": 4, \"mei\": 5, \"juni\": 6,\n",
    "                \"juli\": 7, \"augustus\": 8, \"september\": 9, \"oktober\": 10, \"november\": 11, \"december\": 12,\n",
    "                \"july\": 7, \"october\": 10, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a480b-34b2-45d5-bb2a-9e5fcbb73acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_next_token(position, text):\n",
    "    while position < len(text) - 1 and re.search(\"\\s\", text[position]):\n",
    "        position += 1\n",
    "    token = \"\"\n",
    "    while position < len(text) - 1 and not re.search(\"\\s\", text[position]):\n",
    "        token += text[position]\n",
    "        position += 1\n",
    "    return token, position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2077510-eb9e-44c9-8767-970427f16826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_date_day(position, text):\n",
    "    return number_parser(text[position:])\n",
    "    day = \"\"\n",
    "    next_token, end_position = get_next_token(position, text)\n",
    "    next_next_token, dummy = get_next_token(position + len(next_token) + 1, text)\n",
    "    if cleanup(next_token) in dict(ordinals, **cardinals).keys() and not re.search(\"^en$\", next_next_token, re.IGNORECASE):\n",
    "        day = next_token\n",
    "    elif cleanup(next_token) + \"n\" in dict(ordinals, **cardinals).keys() and not re.search(\"^en$\", next_next_token, re.IGNORECASE):\n",
    "        day = next_token\n",
    "    else:\n",
    "        next_next_token, end_position = get_next_token(position + len(next_token) + 1, text)\n",
    "        next_token += \" \" + next_next_token\n",
    "        next_next_token, end_position = get_next_token(position + len(next_token) + 1, text)\n",
    "        next_token += \" \" + next_next_token\n",
    "        if cleanup(next_token) in dict(ordinals, **cardinals).keys():\n",
    "            day = next_token\n",
    "        elif cleanup(next_token) + \"n\" in dict(ordinals, **cardinals).keys():\n",
    "            day = next_token\n",
    "    if day:\n",
    "        return day, end_position - position\n",
    "    else:\n",
    "        return day, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e9111-45d2-49e0-ab88-803a79672463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_date_month(position, text):\n",
    "    month = \"\"\n",
    "    next_token, end_position = get_next_token(position, text)\n",
    "    if cleanup(next_token) in date_months.keys():\n",
    "        month = next_token\n",
    "    elif re.search(\"-$\", next_token):\n",
    "        next_next_token, next_end_position = get_next_token(end_position, text)\n",
    "        next_token = re.sub(\"-$\", \"\", next_token)\n",
    "        next_token += next_next_token\n",
    "        if cleanup(next_token) in date_months.keys():\n",
    "            month = next_token\n",
    "            end_position = next_end_position\n",
    "    if month:\n",
    "        return month, end_position - position\n",
    "    else:\n",
    "        return month, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f4f9be-d3c3-4a05-bcee-25ad235eb289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_date_year(position, text):\n",
    "    year = \"\"\n",
    "    next_token, next_position = get_next_token(position, text)\n",
    "    if next_token.lower() != \"des\":\n",
    "        return number_parser(text[position:])\n",
    "    next_token, next_position = get_next_token(next_position, text)\n",
    "    return number_parser(text[next_position:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f93c34-3a3f-4648-8cb1-0461c39753da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def longest_number_match(text):\n",
    "    longest_match = \"\"\n",
    "    longest_match_length = 0\n",
    "    text_index = 0\n",
    "    while text_index < len(text) and re.search(\"\\s\", text[text_index]):\n",
    "        text_index += 1\n",
    "    for i in range(text_index, text_index + 25):\n",
    "        phrase = cleanup(text[text_index: i])\n",
    "        if phrase in cardinals.keys() and phrase != longest_match:\n",
    "            longest_match = phrase\n",
    "            longest_match_length = int(i)\n",
    "        elif phrase in ordinals.keys() and phrase != longest_match:\n",
    "            longest_match = phrase\n",
    "            longest_match_length = int(i)\n",
    "        elif phrase in others.keys() and phrase != longest_match:\n",
    "            longest_match = phrase\n",
    "            longest_match_length = int(i)\n",
    "    return longest_match, longest_match_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da031d75-1f94-41d7-9d0c-da8b530a7916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_off_hundreds_thousands(tokens):\n",
    "    if re.search(\".(honderd|duizend)\", tokens[0].lower()):\n",
    "        tokens.insert(0, re.sub(\"(honderd|duizend).*\", \"\", tokens[0].lower()))\n",
    "        tokens[1] = re.sub(\".*(honderd|duizend)\", \"\\\\1\", tokens[1].lower())\n",
    "\n",
    "\n",
    "def number_parser(text):\n",
    "    if not text:\n",
    "        return 0, 0\n",
    "    first_number, first_offset = longest_number_match(text)\n",
    "    second_number, second_offset = longest_number_match(text[first_offset:])\n",
    "    if cleanup(first_number) == \"en\":\n",
    "        number, offset = number_parser(text[first_offset:])\n",
    "        return number, offset + first_offset\n",
    "    if cleanup(first_number) in cardinals:\n",
    "        if cleanup(second_number) == \"honderd\":\n",
    "            number, offset = number_parser(text[first_offset + second_offset:])\n",
    "            return 100 * cardinals[cleanup(first_number)] + number, first_offset + second_offset + offset\n",
    "        if cleanup(second_number) == \"duizend\":\n",
    "            number, offset = number_parser(text[first_offset + second_offset:])\n",
    "            return 1000 * cardinals[cleanup(first_number)] + number, first_offset + second_offset + offset\n",
    "        number, offset = number_parser(text[first_offset:])\n",
    "        return cardinals[cleanup(first_number)] + number, first_offset + offset\n",
    "    if cleanup(first_number) in ordinals:\n",
    "        number, offset = number_parser(text[first_offset:])\n",
    "        return ordinals[cleanup(first_number)] + number, first_offset + offset\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5dd2a3-c2bd-462e-875e-e5480a32c07e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dates(texts, text_id, pattern):\n",
    "    dates = []\n",
    "    text = texts[text_id]\n",
    "    entities = run_bert_pipeline(text)\n",
    "    entities = combine_entities(expand_entities(entities, text))\n",
    "    day = \"\"\n",
    "    positions = find_text_patterns(pattern, text)\n",
    "    for position in positions:\n",
    "        day, token_length_day = get_date_day(position[\"end\"], text)\n",
    "        month, token_length_month = get_date_month(position[\"end\"] + token_length_day, text)\n",
    "        year, token_length_year = get_date_year(position[\"end\"] + token_length_day + token_length_month, text)\n",
    "        dates.append((day,month,year))\n",
    "    return summarize_dates(dates)\n",
    "\n",
    "\n",
    "def complete_date(date):\n",
    "    return date[0] != 0 and date[1] != \"\" and date[2] != 0\n",
    "\n",
    "\n",
    "def contains_complete_date(dates):\n",
    "    if not dates:\n",
    "        return False\n",
    "    elif complete_date(dates[0]):\n",
    "        return True\n",
    "    else:\n",
    "        return contains_complete_date(dates[1:])\n",
    "\n",
    "\n",
    "def summarize_dates(dates_in):\n",
    "    keep_only_complete_dates = contains_complete_date(dates_in)\n",
    "    dates_out = []\n",
    "    for date in dates_in:\n",
    "        (day, month, year) = date\n",
    "        if complete_date(date):\n",
    "            dates_out.append(date)\n",
    "        elif not keep_only_complete_dates and (day != 0 or month != \"\" or year != 0):\n",
    "            dates_out.append(date)\n",
    "    return dates_out    \n",
    "\n",
    "def print_dates(texts, text_id, dates, note=\"\"):\n",
    "    summarized_dates = summarize_dates(dates)\n",
    "    if not summarized_dates:\n",
    "        print_with_color(f\"Text {text_id}: (no dates found)\\n\")\n",
    "    for date in summarize_dates(dates):\n",
    "        (day, month, year) = date\n",
    "        try:\n",
    "            print(f\"Text {text_id}: {day} {month} {year} ({ordinals[cleanup(day)]}-{date_months[cleanup(month)]}-{year}) {note}\")\n",
    "        except:\n",
    "            try:\n",
    "                print(f\"Text {text_id}: {day} {month} {year} ({cardinals[cleanup(day)]}-{date_months[cleanup(month)]}-{year}) {note}\")\n",
    "            except:\n",
    "                if day != 0 and month != \"\" and year != 0:\n",
    "                    print(f\"Text {text_id}: {day} {month} {year} {note}\")\n",
    "                else:\n",
    "                    print_with_color(f\"Text {text_id}: {day} {month} {year} {note}\\n\")\n",
    "\n",
    "def get_death_date(texts, text_id):\n",
    "    dates = get_dates(texts, text_id, \"op den\")\n",
    "    if not dates:\n",
    "        death_dates = get_dates(texts, text_id, \"op\")\n",
    "        document_dates = get_document_date(texts, text_id)\n",
    "        for date in death_dates:\n",
    "            if date[2] != 0:\n",
    "                dates.append(date)\n",
    "            elif document_dates and document_dates[0][2] != 0 and (date[0] != 0 or date[1] != \"\"):\n",
    "                if date_months[cleanup(document_dates[0][1])] < date_months[cleanup(date[1])]:\n",
    "                    dates.append((date[0], date[1], document_dates[0][2] - 1))\n",
    "                else:\n",
    "                    dates.append((date[0], date[1], document_dates[0][2]))\n",
    "            elif not document_dates or document_dates[0][2] == 0:\n",
    "                if date[0] != 0 or date[1] != \"\" or date[2] != 0:\n",
    "                    dates.append(date)\n",
    "    print_dates(texts, text_id, dates)\n",
    "    return dates\n",
    "    \n",
    "    \n",
    "def get_document_date(texts, text_id):\n",
    "    dates = get_dates(texts, text_id, \"heden\")\n",
    "    if not dates:\n",
    "        dates = get_dates(texts, text_id, \"heden den\")\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ddc5b4-df1c-4c3e-a1ee-8d482c9b314f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_and_render_texts({ text_id:texts[text_id] for text_id in texts if text_id == 21})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea38c5-1350-4a1d-ba88-40f865c0ca44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nbr_of_incomplete_dates = 0\n",
    "for text_id in sorted(texts.keys()):\n",
    "    dates = get_death_date(texts, text_id)\n",
    "    for date in dates:\n",
    "        if date[0] == 0 or date[1] == \"\" or date[2] == 0:\n",
    "            nbr_of_incomplete_dates += 1\n",
    "print(f\"number of incomplete dates: {nbr_of_incomplete_dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c03f829-cea2-4b02-b189-69de2dff29fb",
   "metadata": {},
   "source": [
    "**Notes Training set V2:**\n",
    "\n",
    "- 3: spelling error: twinttigsten\n",
    "- 8: spelling error: teen duizend\n",
    "- 18: spelling error: twintigste\n",
    "- 27 spelling error: decemder\n",
    "- 61: spelling error: achtiende\n",
    "\n",
    "**Notes Sample regex:**\n",
    "\n",
    "- 1: extra space\n",
    "- 2: extra space\n",
    "- 5: extra space\n",
    "- 10: spelling error\n",
    "- 12: extra space\n",
    "- 15: spelling error\n",
    "- 19: month as number\n",
    "- 21 no month\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece1f74-276a-4c45-94d4-aa13b0589e8f",
   "metadata": {},
   "source": [
    "## 99. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d541e6b-c428-4084-8f02-85e0457ecd78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924e979-16ef-41d2-a095-6a9bb8a80dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestNotebook(unittest.TestCase):    \n",
    "    def test_process_custom_attrib(self):\n",
    "        self.assertEqual(process_custom_attrib(\"readingOrder {index:1;} certificate_date {offset:10; length:25; continued:true;}\"),\n",
    "                         { 'readingOrder': { 'index': '1' },\n",
    "                           'certificate_date': { 'offset': '10', 'length': '25', 'continued': 'true' } } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cfecd-5676-48e4-9412-6654f7ae0f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a5fa3-e97d-4569-84cb-52b42e50a066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
