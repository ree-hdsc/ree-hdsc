{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1acff869-67df-4b20-a939-86b1b609059e",
   "metadata": {},
   "source": [
    "# Info fields via machine learning\n",
    "\n",
    "Extract persons from the info fields StartEntryInfo and EndEntryInfo of the [slave registers of Suriname](https://datasets.iisg.amsterdam/dataset.xhtml?persistentId=hdl:10622/CSPBHO) via machine learning\n",
    "\n",
    "See: https://www.freecodecamp.org/news/getting-started-with-ner-models-using-huggingface/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16afe6d3-87bf-4c94-b48d-9cf0b81c1a4c",
   "metadata": {},
   "source": [
    "## 1. Annotating info fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39531b3-deb1-4d22-9586-de290836ee04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "import regex\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8ca70-3fd4-4d1b-8cff-a2815842e39c",
   "metadata": {},
   "source": [
    "### 1.1 Read relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa999620-9243-433e-9e92-63ffa5607c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_FILE = \"../../data/suriname/Dataset Suriname Slave and Emancipation Registers Version 1.1.csv\"\n",
    "DATA_COLUMN = \"StartEntryInfo\"\n",
    "\n",
    "data = pd.read_csv(DATA_FILE, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cdd66-c9bc-40f4-a145-73228319d7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_column_tokens(train):\n",
    "    train[\"tokens\"] = [ nltk.word_tokenize(text) for text in train[\"text\"] ]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3f692-e25b-4fca-aed5-98c2b8211153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_column_labels(train):\n",
    "    train[\"labels\"] = [ len(tokens) * [ \"O\" ] for tokens in train[\"tokens\"] ]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d22f9b5-a3c3-46d7-b0fb-34a7b2f37581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_column_numeric_labels(train, numeric_labels):\n",
    "    train[\"numeric_labels\"] = [ [ numeric_labels[label] for label in labels ] for labels in train[\"labels\"] ]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17279108-eb94-46c0-87ed-655e84eeeef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_date(day, month, year):\n",
    "    return regex.search(r\"^\\d\\d\\d\\d\\b\", year) and regex.search(r\"^\\d\\d?$\", day) and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09845b-a11a-46e3-8041-ac4128800650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_date_tags_to_labels(labels, index):\n",
    "    labels[index - 2], labels[index - 1], labels[index] = \"B-DATE\", \"I-DATE\", \"I-DATE\"\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ca68a-b24e-4f94-b1d0-a05737cc549e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_dates(train):\n",
    "    for index, row in train.iterrows():\n",
    "        for i in range(2, len(row[\"tokens\"])):\n",
    "            if is_date(row[\"tokens\"][i-2], row[\"tokens\"][i-1], row[\"tokens\"][i]):\n",
    "                add_date_tags_to_labels(row[\"labels\"], i)\n",
    "    return train       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333bfb9-6b81-4ce5-9927-12a1e86d7d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_annotations(train):\n",
    "    for index in range(0, len(train)):\n",
    "        for i in range(0, len(train[\"labels\"][index])):\n",
    "            print(train[\"tokens\"][index][i], end=\"\")\n",
    "            if train[\"labels\"][index][i] != \"O\":\n",
    "                print(\"/\" + train[\"labels\"][index][i], end=\"\")\n",
    "            print(\" \", end=\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863fe91b-e883-406e-b7af-eb8f7a198a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_train(data, nbr_of_lines=100):\n",
    "    if nbr_of_lines > 0:\n",
    "        train = pd.DataFrame(data[DATA_COLUMN].value_counts()[:nbr_of_lines])\n",
    "    else:\n",
    "        train = pd.DataFrame(data[DATA_COLUMN].value_counts())\n",
    "    train = train.rename(columns={DATA_COLUMN: \"frequency\"})\n",
    "    train[\"text\"] = train.index\n",
    "    train[\"index\"] = range(0, len(train))\n",
    "    train = train.set_index(\"index\")\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27aff36-ce1e-472c-963c-c23dcf63b316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info_data_train = make_train(data, nbr_of_lines=0)\n",
    "info_data_train = add_column_tokens(info_data_train)\n",
    "info_data_train = add_column_labels(info_data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d70616-ba02-4cb8-9c7e-6c0eebbebc05",
   "metadata": {},
   "source": [
    "### 1.2 Make data for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a1e97-4794-457a-ba96-383fac6fc17c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SELECTED_FREQUENT = 100\n",
    "SELECTED_RANDOM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ded55-aebe-4f6f-b071-7263a04d4a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_selected_data_ids(info_data_train, selected_frequent=SELECTED_FREQUENT, selected_random=SELECTED_RANDOM):\n",
    "    selected_data_ids = list(range(0, selected_frequent))\n",
    "    while len(selected_data_ids) < selected_frequent + selected_random:\n",
    "        selected_data_id = random.randint(selected_frequent, len(info_data_train) - 1)\n",
    "        if selected_data_id not in selected_data_ids:\n",
    "            selected_data_ids.append(selected_data_id)\n",
    "    return selected_data_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c2de4-534d-4447-b1af-3180ea593242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_selected_data_flags(info_data_train, selected_data_ids):\n",
    "    selected_data_flags = len(info_data_train) * [ False ]\n",
    "    for id_value in selected_data_ids:\n",
    "        selected_data_flags[id_value] = True\n",
    "    return selected_data_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f518425-2956-41d4-a8fa-04a382eade0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_annotated_data(info_data_train, selected_data_flags):\n",
    "    out_file = open(\"outfile.json\", \"w\")\n",
    "    selected_data = []\n",
    "    for index, row in info_data_train[selected_data_flags].iterrows():\n",
    "        text = \" \".join(row[\"tokens\"])\n",
    "        selected_data.append({ \"eid\": DATA_COLUMN[0] + str(index), \"text\": text, \"label\": [] })\n",
    "        print(selected_data[-1], file=out_file)\n",
    "    out_file.close()\n",
    "    return selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c62af9-2653-48fe-b0ca-49bc18752081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_data(info_data_train, selected_frequent=SELECTED_FREQUENT, selected_random=SELECTED_RANDOM):\n",
    "    random.seed(42)\n",
    "    selected_data_ids = make_selected_data_ids(info_data_train, selected_frequent, selected_random)\n",
    "    selected_data_flags = make_selected_data_flags(info_data_train, selected_data_ids)\n",
    "    selected_data = save_annotated_data(info_data_train, selected_data_flags)\n",
    "    return selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6687544-ff14-4a42-936b-90ff68cd0af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_data = make_data(info_data_train, selected_frequent=SELECTED_FREQUENT, selected_random=SELECTED_RANDOM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b9dcc-b26a-49a2-b5ed-ea25e6cd6d1b",
   "metadata": {},
   "source": [
    "### 1.3 Read annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2394b87-dfac-4e39-afd8-9dec35cb68dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ANNOTATIONS_FILE = \"../../data/annotated/600.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b241a2c-4d89-4bd3-99b3-2883a61737bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_offset2label_pos(text):\n",
    "    offset2label_pos = {}\n",
    "    offset = 0\n",
    "    token_counter = 0\n",
    "    for token in text.split():\n",
    "        offset2label_pos[offset] = token_counter\n",
    "        offset += len(token) + 1\n",
    "        token_counter += 1\n",
    "    return offset2label_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e4822-9585-48ba-82bf-88416b1f6201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_label_start_not_token_initial(text, label_start):\n",
    "    while regex.search(\" \", text[label_start]):\n",
    "        label_start += 1\n",
    "    while label_start > 0 and not regex.search(\" \", text[label_start - 1]):\n",
    "        label_start -= 1\n",
    "    return label_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff681a-79fc-488d-830b-11e36a17bccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_labels(data):\n",
    "    text = data[\"data\"]\n",
    "    labels = [ \"O\" for token in text.split() ]\n",
    "    offset2label_pos = make_offset2label_pos(text)\n",
    "    for label in data[\"label\"]:\n",
    "        label[0] = fix_label_start_not_token_initial(text, label[0])\n",
    "        if label[0] not in offset2label_pos:\n",
    "            raise Exception(f\"{label[0]} not found in labels {offset2label_pos} of text {text}\")\n",
    "        else:\n",
    "            labels[offset2label_pos[label[0]]] = \"B-\" + label[2]\n",
    "            for i in range(label[0] + 1, label[1] + 1):\n",
    "                if i in offset2label_pos:\n",
    "                    labels[offset2label_pos[i]] = \"I-\" + label[2]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea277fd-a04c-421e-a4e9-b43c95fcf353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_jsonl_file(file_name):\n",
    "    annotations_file = open(file_name, \"r\")\n",
    "    texts = []\n",
    "    tags = []\n",
    "    for line in annotations_file:\n",
    "        data = json.loads(line)\n",
    "        texts.append(data[\"data\"].split())\n",
    "        tags.append(make_labels(data))\n",
    "    annotations_file.close()\n",
    "    return texts, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87610b03-fd82-46fc-b491-af84c13c43a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts, tags = read_jsonl_file(ANNOTATIONS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa63a6-fd28-4e27-bcf0-13b35794976c",
   "metadata": {},
   "source": [
    "## 2. Machine learning\n",
    "\n",
    "Based on tutorial https://huggingface.co/transformers/v3.2.0/custom_datasets.html#token-classification-with-w-nut-emerging-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed17038-ae39-4b27-9185-f14863fcbfb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import regex\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy import displacy\n",
    "import torch\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416ec63-1bf8-4d78-8324-4e690d8b8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_text(text, entities):\n",
    "    displacy.render({ \"text\": regex.sub(\"\\\\n\", \" \", text), \n",
    "                      \"ents\": entities }, \n",
    "                      options = { \"colors\": { \"fuzzy_match\": \"yellow\"} }, style = \"ent\", manual = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b951f-cea5-4fe2-9cca-909f38f371c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_text(\"a bee sees the eee\", [ { \"start\": 2, \"end\": 5, \"label\": \"test\" } ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593d8cf-b441-4ee9-aabe-c4c25caa6ee5",
   "metadata": {},
   "source": [
    "### 2.1 Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45aea3f-482a-4421-ab09-6abb206d8c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_missing_I_tags(tags):\n",
    "    missing_tags = []\n",
    "    for tag in tags:\n",
    "        i_tag = regex.sub(r\"^B-\", \"I-\", tag)\n",
    "        if i_tag not in tags:\n",
    "            missing_tags.append(i_tag)\n",
    "    return list(tags) + missing_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904cbe0e-f7ea-4bdc-9854-60cb9838fa55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_tags, val_tags = train_test_split(texts, tags, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2ee85-783f-4af8-bac2-b5a1f012d16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_tags = set(tag for doc in tags for tag in doc )\n",
    "unique_tags = add_missing_I_tags(unique_tags)\n",
    "unique_types = list(set([ regex.sub(r\"^[BI]-\", \"\", tag) for tag in unique_tags ]))\n",
    "tag2id = { tag: id for id, tag in enumerate(unique_tags) }\n",
    "id2tag = { id: tag for tag, id in tag2id.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974af327-db79-4dd6-b93a-ca1d707bdd3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96866fb1-e997-46e9-9148-04e45c534e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, \n",
    "                            is_split_into_words=True, \n",
    "                            return_offsets_mapping=True, \n",
    "                            padding=True, \n",
    "                            truncation=True)\n",
    "val_encodings =   tokenizer(val_texts, \n",
    "                            is_split_into_words=True, \n",
    "                            return_offsets_mapping=True, \n",
    "                            padding=True, \n",
    "                            truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e4673-8459-42ee-a5aa-221306002e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_B_to_I_tag(tag):\n",
    "    return regex.sub(r\"^B\", \"I\", tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f431ba-9046-47cd-a82a-d0441193e59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_tags(tags_in, encodings):\n",
    "    tags_out = [ [] for _ in range(len(encodings.offset_mapping,)) ]\n",
    "    for encodings_doc, tags_in_doc, tags_out_doc in zip(encodings.offset_mapping, tags_in, tags_out):\n",
    "        CLS_seen = False\n",
    "        SEP_seen = False\n",
    "        tags_counter = 0\n",
    "        for encoding in encodings_doc:\n",
    "            if encoding[1] == 0:\n",
    "                if not CLS_seen:\n",
    "                    tags_out_doc.append(\"CLS\")\n",
    "                    CLS_seen = True\n",
    "                elif not SEP_seen:\n",
    "                    tags_out_doc.append(\"SEP\")\n",
    "                    SEP_seen = True\n",
    "                else:\n",
    "                    tags_out_doc.append(\"PAD\")\n",
    "            elif encoding[0] == 0:\n",
    "                tags_out_doc.append(tags_in_doc[tags_counter])\n",
    "                tags_counter += 1\n",
    "            else:\n",
    "                tags_out_doc.append(convert_B_to_I_tag(tags_in_doc[tags_counter - 1]))\n",
    "    return tags_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02cee79-11ae-4a73-af85-82bba30cb4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tags_to_numbers(tags, tag2id):\n",
    "    return [ [ tag2id[tag] for tag in doc ] for doc in tags ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ec5ba-1445-4714-b326-66c46eea3719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IGNORE_TAG = -100\n",
    "\n",
    "extra_tags = { 'CLS': IGNORE_TAG, 'SEP': IGNORE_TAG, 'PAD': IGNORE_TAG }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671b280-dcf8-4bce-9c1e-4a73b64305ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = tags_to_numbers( split_tags(train_tags, train_encodings),\n",
    "                                { **tag2id, **extra_tags})\n",
    "val_labels =   tags_to_numbers( split_tags(val_tags, val_encodings),\n",
    "                                { **tag2id, **extra_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba62d6-0caa-49f7-a63f-bfcc242e745c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WNUTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346470a9-6199-45e6-8948-23b45c1f36d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
    "val_encodings.pop(\"offset_mapping\")\n",
    "train_dataset = WNUTDataset(train_encodings, train_labels)\n",
    "val_dataset = WNUTDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1aa58a-c202-4004-b27d-589a995c97f7",
   "metadata": {},
   "source": [
    "### 2.2 Fine-tune model with data\n",
    "\n",
    "Using Bertje as base model: https://huggingface.co/GroNLP/bert-base-dutch-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0975a-154d-4e20-a9fb-8454a47b6822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"GroNLP/bert-base-dutch-cased\", num_labels=len(unique_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7304d-d4fb-4314-bdd5-8451b149f87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=7,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf4f40f-ef07-49f2-81a5-1c313d9d24d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ff458-e1b9-4f9d-a906-a4c764fd34bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_data = { 400: [[ 10 , 2.973100 , 2.855659], [20 ,2.874400 ,2.633519], [30 ,2.598700 ,2.267503], [40 ,2.211500 ,1.768432], [50 ,1.778300 ,1.324655],\n",
    "[60, 1.550900, 1.093353], [70, 1.220000, 0.903201], [80, 1.011200, 0.697839], [90 ,0.778800 ,0.554128], [100 ,0.623100 ,0.440024],\n",
    "[110, 0.488200, 0.349560], [120, 0.343000, 0.288387], [130, 0.300600, 0.250258], [140, 0.226900, 0.229932], [150, 0.170800, 0.200462],\n",
    "[160, 0.173200, 0.177333], [170, 0.101600, 0.182475], [180, 0.108400, 0.170770], [190, 0.074900, 0.172628], [200, 0.075700, 0.177106],\n",
    "[210, 0.054100, 0.168911], [220, 0.047600, 0.179788], [230, 0.038200, 0.168373], [240, 0.039000, 0.165006], [250, 0.030100, 0.163445],\n",
    "[260, 0.027400, 0.174015], [270, 0.018400, 0.171961], [280, 0.024600, 0.178531], [290, 0.015000, 0.189336], [300, 0.019300, 0.185390],\n",
    "[310, 0.014100, 0.179444], [320, 0.009900, 0.196208], [330, 0.017200, 0.177975], [340, 0.007100, 0.188561], [350, 0.011200, 0.175972],\n",
    "[360, 0.006600, 0.179566], [370, 0.007400, 0.180530], [380, 0.012900, 0.199687], [390, 0.005000, 0.191614], [400, 0.003700, 0.178989]],\n",
    "600: [ [10, 2.853400, 2.788824], [20, \t2.739800, \t2.618280], [30, 2.518100, 2.352505], [40, 2.215600, 2.010691], [50, 1.876800, 1.643065],\n",
    "[60, 1.569300, 1.363279], [70, 1.279300, 1.098443], [80, 1.041300, 0.855244], [90, 0.854200, 0.671153], [100, 0.616700, 0.533351],\n",
    "[110, 0.562700, 0.431195], [120, 0.449400, 0.350870], [130, 0.334900, 0.301453], [140, 0.261000, 0.252131], [150, 0.290400, 0.220683],\n",
    "[160, 0.190300, 0.203238], [170, 0.154600, 0.190547], [180, 0.185800, 0.167484], [190, 0.108400, 0.160793], [200, 0.101400, 0.145170],\n",
    "[210, 0.088100, 0.133172], [220, 0.081000, 0.135661], [230, 0.068500, 0.159878], [240, 0.052700, 0.146953], [250, 0.038300, 0.169547],\n",
    "[260, 0.037700, 0.152970], [270, 0.065600, 0.140576], [280, 0.027200, 0.173946], [290, 0.022900, 0.149843], [300, 0.023700, 0.155466]] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddd835-1afe-4b47-b040-4dc8ea85d24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718af7d-9af4-4a33-ba82-521494e4f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eval_data(eval_data):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.plot([data[0] for data in eval_data], [data[1] for data in eval_data], label=\"training loss\")\n",
    "    plt.plot([data[0] for data in eval_data], [data[2] for data in eval_data], label=\"validation loss\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75d44c-f745-450c-9688-7b8b1719a6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_eval_data(eval_data[600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f621a4-b656-4e2f-befb-4a7aa7ddafe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3713cb-1c14-4cc4-9f10-577a5acf8406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = trainer.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495cd6f2-1232-46a3-984b-87f230ac8aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_precision_and_recall(correct_count, missed_count, wrong_count):\n",
    "    for tag in sorted(correct_count):\n",
    "        if correct_count[tag] > 0 or missed_count[tag] or wrong_count[tag] > 0:\n",
    "            precision = correct_count[tag]/(correct_count[tag] + wrong_count[tag])\n",
    "            recall = correct_count[tag]/(correct_count[tag] + missed_count[tag])\n",
    "            print(f\"precision: {precision:.2f}; recall: {recall:.2f}; count: {correct_count[tag] + missed_count[tag]:4d}; tag: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab46522-649d-4ea7-8250-49d0a0d2eebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_results(results):\n",
    "    correct_count = { tag: 0 for tag in unique_types + [ \"\" ] }\n",
    "    missed_count = { tag: 0 for tag in unique_types + [ \"\" ] }\n",
    "    wrong_count = { tag: 0 for tag in unique_types + [ \"\" ] }\n",
    "    for guesses, corrects in zip(results[0], results[1]):\n",
    "        for guess_values, correct_id in zip(guesses, corrects):\n",
    "            if correct_id != IGNORE_TAG:\n",
    "                guess_id = list(guess_values).index(max(guess_values))\n",
    "                if correct_id != tag2id['O'] and guess_id == correct_id:\n",
    "                    correct_count[\"\"] += 1\n",
    "                else:\n",
    "                    if correct_id != tag2id['O']:\n",
    "                        missed_count[\"\"] += 1\n",
    "                    if guess_id != tag2id['O']:\n",
    "                        wrong_count[\"\"] += 1\n",
    "                correct_tag = regex.sub(r\"^[BI]-\", \"\", id2tag[int(correct_id)])\n",
    "                guess_tag = regex.sub(r\"^[BI]-\", \"\", id2tag[int(guess_id)])\n",
    "                if correct_tag != 'O' and guess_tag == correct_tag:\n",
    "                    correct_count[correct_tag] += 1\n",
    "                else:\n",
    "                    if correct_tag != 'O':\n",
    "                        missed_count[correct_tag] += 1\n",
    "                    if guess_tag != 'O':\n",
    "                        wrong_count[guess_tag] += 1                \n",
    "    return correct_count, missed_count, wrong_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35201e78-1541-42f4-93b8-c0a16a87c368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correct_count, missed_count, wrong_count = evaluate_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695bee3-8b41-4c83-bccb-0654b8628e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_precision_and_recall(correct_count, missed_count, wrong_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8d392-c47b-4de3-b3d3-6095b67c2823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_results(results, encodings, max_counter=0):\n",
    "    counter = 0\n",
    "    for guess_data, correct_data, token_data in zip(results[0], results[1], encodings):\n",
    "        text = \"\"\n",
    "        tags = []\n",
    "        for guess_values, correct_id, token in zip(guess_data, correct_data, tokenizer.convert_ids_to_tokens(token_data)):\n",
    "            guess_id = list(guess_values).index(max(guess_values))\n",
    "            if correct_id != IGNORE_TAG:\n",
    "                if guess_id != IGNORE_TAG and guess_id != tag2id['O']:\n",
    "                    tags.append({ \"start\": len(text), \"end\": len(text) + len(token), \"label\": regex.sub(r\"^[BI]-\", \"\", id2tag[guess_id])[0]})\n",
    "                text = text + token + \" \"\n",
    "        render_text(text, tags)\n",
    "        counter += 1\n",
    "        if max_counter > 0 and counter >= max_counter:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b4c61-9ae4-4023-959e-75e1e565a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_results(results, val_encodings.input_ids, max_counter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6affb-b542-4a7c-8697-b07cc62dfb72",
   "metadata": {},
   "source": [
    "### 2.3 Process text with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf693eb-e340-456f-9bc1-986b240ec30b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c3a5e-9fde-4733-a60f-6a2d34af7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea0a7b-cbcd-4e67-8286-c29005fd746e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = make_data(info_data_train, selected_frequent=100, selected_random=100)\n",
    "extra_data = make_data(info_data_train, selected_frequent=100, selected_random=1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047da473-bb0f-4ccc-ac9b-cdc47b87f661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_extra_data = []\n",
    "for data in extra_data:\n",
    "    if data not in train_data:\n",
    "        tag_counter = 0\n",
    "        for entity in ner_pipeline(data[\"text\"]):\n",
    "            label = id2tag[int(regex.sub(\"LABEL_\", \"\", entity[\"entity\"]))]\n",
    "            if regex.search(\"(ENSLAVED|FREED|OWNER)\", label):\n",
    "                tag_counter += 1\n",
    "        if tag_counter > 0:\n",
    "            selected_extra_data.append({ \"tag_counter\": tag_counter, \"data\": data })\n",
    "len(selected_extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be37cbe-1605-451d-acf9-f1d84a4a59e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_file = open(\"outfile.json\", \"w\")\n",
    "for data in sorted(selected_extra_data, key=lambda data: data[\"tag_counter\"], reverse=True)[:100]:\n",
    "    #data[\"data\"].pop(\"eid\", None)\n",
    "    print(json.dumps(data[\"data\"]), file=out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637ae30-9a6c-4ab7-9ab7-ff48c320abc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
