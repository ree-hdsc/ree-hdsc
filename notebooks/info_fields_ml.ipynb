{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1acff869-67df-4b20-a939-86b1b609059e",
   "metadata": {},
   "source": [
    "# Info fields via machine learning\n",
    "\n",
    "Extract persons from the info fields StartEntryInfo and EndEntryInfo of the [slave registers of Suriname](https://datasets.iisg.amsterdam/dataset.xhtml?persistentId=hdl:10622/CSPBHO) via machine learning\n",
    "\n",
    "See: https://www.freecodecamp.org/news/getting-started-with-ner-models-using-huggingface/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16afe6d3-87bf-4c94-b48d-9cf0b81c1a4c",
   "metadata": {},
   "source": [
    "## 1. Annotating info fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39531b3-deb1-4d22-9586-de290836ee04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import regex\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa999620-9243-433e-9e92-63ffa5607c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_FILE = \"../../data/suriname/Dataset Suriname Slave and Emancipation Registers Version 1.1.csv\"\n",
    "\n",
    "data = pd.read_csv(DATA_FILE, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cdd66-c9bc-40f4-a145-73228319d7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_column_tokens(train):\n",
    "    train[\"tokens\"] = [ nltk.word_tokenize(text) for text in train[\"text\"] ]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3f692-e25b-4fca-aed5-98c2b8211153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_column_labels(train):\n",
    "    train[\"labels\"] = [ len(tokens) * [ \"O\" ] for tokens in train[\"tokens\"] ]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d22f9b5-a3c3-46d7-b0fb-34a7b2f37581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_column_numeric_labels(train, numeric_labels):\n",
    "    train[\"numeric_labels\"] = [ [ numeric_labels[label] for label in labels ] for labels in train[\"labels\"] ]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17279108-eb94-46c0-87ed-655e84eeeef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_date(day, month, year):\n",
    "    return regex.search(r\"^\\d\\d\\d\\d\\b\", year) and regex.search(r\"^\\d\\d?$\", day) and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09845b-a11a-46e3-8041-ac4128800650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_date_tags_to_labels(labels, index):\n",
    "    labels[index - 2], labels[index - 1], labels[index] = \"B-DATE\", \"I-DATE\", \"I-DATE\"\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ca68a-b24e-4f94-b1d0-a05737cc549e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_dates(train):\n",
    "    for index, row in train.iterrows():\n",
    "        for i in range(2, len(row[\"tokens\"])):\n",
    "            if is_date(row[\"tokens\"][i-2], row[\"tokens\"][i-1], row[\"tokens\"][i]):\n",
    "                add_date_tags_to_labels(row[\"labels\"], i)\n",
    "    return train       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333bfb9-6b81-4ce5-9927-12a1e86d7d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_annotations(train):\n",
    "    for index in range(0, len(train)):\n",
    "        for i in range(0, len(train[\"labels\"][index])):\n",
    "            print(train[\"tokens\"][index][i], end=\"\")\n",
    "            if train[\"labels\"][index][i] != \"O\":\n",
    "                print(\"/\" + train[\"labels\"][index][i], end=\"\")\n",
    "            print(\" \", end=\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863fe91b-e883-406e-b7af-eb8f7a198a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_train(data, nbr_of_lines=50):\n",
    "    train = pd.DataFrame(data[\"EndEntryInfo\"].value_counts()[:nbr_of_lines])\n",
    "    train = train.rename(columns={\"EndEntryInfo\": \"frequency\"})\n",
    "    train[\"text\"] = train.index\n",
    "    train[\"index\"] = range(0, len(train))\n",
    "    train = train.set_index(\"index\")\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27aff36-ce1e-472c-963c-c23dcf63b316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = make_train(data)\n",
    "train = add_column_tokens(train)\n",
    "train = add_column_labels(train)\n",
    "train = label_dates(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa421d11-bdd2-47ef-aa24-a797afc94609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_labels = { \"O\": 0, \"B-DATE\": 1, \"I-DATE\": 2 }\n",
    "\n",
    "train = add_column_numeric_labels(train, numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e54e5e-7129-4eb2-9902-a56d016b0ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"wietsedv/bert-base-dutch-cased-finetuned-udlassy-ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ea959-f4f5-4044-aeb7-9b22c3d6fc71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(train[\"tokens\"][0], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6a4dd-5d93-4512-bbf6-967c60fe89a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361e66b-1c00-4eb2-a874-0e1d3926c310",
   "metadata": {},
   "source": [
    "## 2. Tutorial\n",
    "\n",
    "https://huggingface.co/docs/transformers/tasks/token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22044aaa-ab08-494d-bda8-0319e14c3ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install transformers datasets evaluate seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab50c05-4168-4eeb-842b-3a138fbfeb1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b5c93-e02a-46b1-9ad9-ba62c01b475f",
   "metadata": {},
   "source": [
    "### 2.1 Setting up tutodial data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff921774-b61f-4f08-bad3-9af4b68f38e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wnut = load_dataset(\"wnut_17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca475d-bdce-4cbf-a6bc-196220a43ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in wnut:\n",
    "    print(key, len(wnut[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61918306-acd9-4ca1-b005-86a3db3a8991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wnut[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec435af8-3f16-423f-9d19-f1486115e9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list = wnut[\"train\"].features[f\"ner_tags\"].feature.names\n",
    "\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427264eb-8aa4-426c-b29d-d10a2900d995",
   "metadata": {},
   "source": [
    "### 2.2 Setting up info fields data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000904e-f330-4a40-b81c-7de5963fcf27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_info_field_data(train):\n",
    "    info_fields_data = {}\n",
    "    info_fields_data[\"train\"] = dataset_dict.Dataset([ { \"id\": i, \"tokens\": train[\"tokens\"][i], \"ner_tags\": train[\"labels\"][i] } \n",
    "                                                       for i in range(0, int(0.5 + 0.6 * len(train))) ])\n",
    "    info_fields_data[\"test\"] = dataset_dict.Dataset([ { \"id\": i, \"tokens\": train[\"tokens\"][i], \"ner_tags\": train[\"labels\"][i] } \n",
    "                                                      for i in range(int(0.5 + 0.6 * len(train)), len(train)) ])\n",
    "    info_fields_data[\"validation\"] = info_fields_data[\"test\"]\n",
    "    return dataset_dict.DatasetDict(info_fields_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d51e8-6e93-4ffe-a3c6-439031176767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info_fields_data = make_info_field_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4530373-536c-437f-acbd-24954d16ea39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info_fields_label_list = list(numeric_labels.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c62054-ddc9-4eae-a3a7-0bd795f25760",
   "metadata": {},
   "source": [
    "### 2.3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c920eb-76e3-428a-9c1f-3620f2fbba96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e28c1a-f5ce-4138-a68f-155009b946be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = info_fields_data\n",
    "label_list = info_fields_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a57f6-c908-4b34-9eae-05dcbb47f97e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example = training_data[\"train\"][0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab744e1e-93fd-4e2e-92fb-a7ce7938fd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca32c24-797d-4ed9-aa1b-46f77db3943e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46bf1c1-dd30-4999-babb-06d2e34e03b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_training_data = training_data.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c51a83-9c77-44a9-8a38-2c58426f7edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfcc4c-3198-4a56-be29-a7038e973b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f053e4-3380-40d5-a278-64b095aa5a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = [label_list[i] for i in example[f\"ner_tags\"]]\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb284e-6635-4d76-89a5-9a5af520bd98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"O\",\n",
    "    1: \"B-corporation\",\n",
    "    2: \"I-corporation\",\n",
    "    3: \"B-creative-work\",\n",
    "    4: \"I-creative-work\",\n",
    "    5: \"B-group\",\n",
    "    6: \"I-group\",\n",
    "    7: \"B-location\",\n",
    "    8: \"I-location\",\n",
    "    9: \"B-person\",\n",
    "    10: \"I-person\",\n",
    "    11: \"B-product\",\n",
    "    12: \"I-product\",\n",
    "}\n",
    "label2id = {\n",
    "    \"O\": 0,\n",
    "    \"B-corporation\": 1,\n",
    "    \"I-corporation\": 2,\n",
    "    \"B-creative-work\": 3,\n",
    "    \"I-creative-work\": 4,\n",
    "    \"B-group\": 5,\n",
    "    \"I-group\": 6,\n",
    "    \"B-location\": 7,\n",
    "    \"I-location\": 8,\n",
    "    \"B-person\": 9,\n",
    "    \"I-person\": 10,\n",
    "    \"B-product\": 11,\n",
    "    \"I-product\": 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d1d0d6-61fd-42c6-8fe3-d8a877924a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=13, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62f80c-7fef-417d-b6d9-7ac3f903796e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_wnut_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False, ### <--- changed\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_wnut[\"train\"],\n",
    "    eval_dataset=tokenized_wnut[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89c878c1-81de-4539-814e-ab0139bc9fcd",
   "metadata": {},
   "source": [
    "Epoch \tTraining Loss \tValidation \tPrecision \tRecall \tF1 \tAccuracy\n",
    "        1 \tNo log \t0.282456 \t0.528226 \t0.242817 \t0.332698 \t0.937711\n",
    "        2 \tNo log \t0.274149 \t0.559853 \t0.281742 \t0.374846 \t0.940832\n",
    "\n",
    "Epoch \tTraining Loss \tValidation \tPrecision \tRecall \tF1 \tAccuracy\n",
    "        1 \tNo log \t0.255242 \t0.501940 \t0.359592 \t0.419006 \t0.943226\n",
    "        2 \tNo log \t0.282641 \t0.562500 \t0.358665 \t0.438031 \t0.945791"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28dffad-756c-43d8-a644-e6aa2422358a",
   "metadata": {},
   "source": [
    "### 2.4 Post-training tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed2f7c-78e0-45aa-862c-f0fc7b427c23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"The Golden State Warriors are an American professional basketball team based in San Francisco.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8d6d8-6b2a-4584-973a-1c19caae5dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SKIP\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"ner\", \"stevhliu/my_awesome_wnut_model\")\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33018a-db43-408c-8c6a-4ae061348c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SKIP\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stevhliu/my_awesome_wnut_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37db521-d00a-4e25-a907-b2049c143bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SKIP\n",
    "from transformers import AutoModelForTokenClassification\n",
    "import torch\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"stevhliu/my_awesome_wnut_model\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae240a94-eb9c-4934-8d2b-55ad31866d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd1a4c-64a3-4bed-ae67-fabe8e259220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bea111-be87-48c7-883e-8c16d00b9624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ab58f-4bbc-4a11-9764-223c8ddb4d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = torch.argmax(logits, dim=2)\n",
    "predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]]\n",
    "predicted_token_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc80c70-21ce-4b42-9a0b-5a6a4a4955e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
