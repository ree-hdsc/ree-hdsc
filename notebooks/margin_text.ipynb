{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ee9228c-c768-44eb-846b-1adb249de592",
   "metadata": {},
   "source": [
    "# Process margin texts of birth certificates of Suriname 1828-1921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce1f42d-1dbe-4797-b5cd-1993ae3c3c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import regex\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "from IPython.display import clear_output\n",
    "from scripts import ner_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3612bc5-e72a-452d-aa6e-175191514eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeal(text=None):\n",
    "    clear_output(wait=True)\n",
    "    if not text is None:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5050a-c798-4437-9526-a0a0c1925cf5",
   "metadata": {},
   "source": [
    "## 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1500225-0b7b-48b8-b5ce-43c5ef09b4cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_file = \"../../data/kantmeldingen.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0216fbc2-38fa-4ffd-85d4-70b0ebfb90c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5e953-92c6-4e76-a8b8-5c8dd5e00772",
   "metadata": {},
   "source": [
    "## 2. Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfda0f4-4a08-4512-a2c4-559e0444bed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae66cf-f460-4a2e-8a03-8058dc6caf37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in data:\n",
    "    print(key, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801df96-8881-41ca-acf6-ab1f91623bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "birth_date_list = list(data[\"birth_date\"])\n",
    "birth_year_list = []\n",
    "for birth_date in birth_date_list:\n",
    "    try:\n",
    "        birth_year = birth_date[6:10]\n",
    "        if len(birth_year) == 4:\n",
    "            birth_year_list.append(int(birth_year))\n",
    "    except:\n",
    "        pass\n",
    "print(sorted(birth_year_list)[:10], sorted(birth_year_list)[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aab5eb-7ee8-4fe0-b55c-1cf2b53ef2b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_rows(column, value):\n",
    "    return data[data[column].apply(lambda x: bool(re.search(value, x, re.IGNORECASE)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476acdf1-b96d-4299-ad91-5c1196fe678f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "find_rows(\"birth_date\", \"1988\")[\"birth_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb605b3-6a1c-4b2c-97a5-7d11e3b98333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"note_type\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c3356-a618-4af7-b28d-45c4e9dd0f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"note_type_other\"].value_counts(dropna=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2592d6-df66-40df-bb74-1bd08f2c507e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"note_txt\"][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1473f426-4280-45fd-ba0a-eafaabaa43cb",
   "metadata": {},
   "source": [
    "## 3. Find entities with standard Dutch NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431899f2-1f8d-46f8-933e-1b30ed3465ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ner_analysis_process = ner_analysis.NerAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb75cad-0d0b-454d-806a-6bd7e9347d28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = data[\"note_txt\"][9]\n",
    "entity_tokens = ner_analysis_process.process(data[\"note_txt\"][9])\n",
    "ner_analysis_process.render_text(text, entity_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c661bf8-6043-44bc-a374-494184cdf001",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d79d7e-21f0-4f8e-bee8-6d51e9034280",
   "metadata": {},
   "source": [
    "## 4. Find entities with slave register NER\n",
    "\n",
    "Code copied from noteb ook info_fields_ml.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55612d87-8743-445c-a414-c28493bc06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import BertForTokenClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57877ab6-be5c-4ce4-a286-f696f69602bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_TAG_ID = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e7db3-3c12-4b8c-9716-f646d1f57df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2tag = { 0: 'B-DATE',\n",
    " 1: 'B-ENSLAVED',\n",
    " 2: 'B-FOLIO',\n",
    " 3: 'B-FREED',\n",
    " 4: 'B-OWNER',\n",
    " 5: 'B-PLANT',\n",
    " 6: 'B-RESNR',\n",
    " 7: 'B-TOPIC',\n",
    " 8: 'I-DATE',\n",
    " 9: 'I-ENSLAVED',\n",
    " 10: 'I-FOLIO',\n",
    " 11: 'I-FREED',\n",
    " 12: 'I-OWNER',\n",
    " 13: 'I-PLANT',\n",
    " 14: 'I-RESNR',\n",
    " 15: 'I-TOPIC',\n",
    " 16: 'O'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb6ba8-0241-452d-8c57-bcdc1cd71cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tags(id2tag):\n",
    "    tag2id = { id2tag[key]: key for key in id2tag }\n",
    "    unique_tags = list(tag2id.keys())\n",
    "    unique_types = list(set([ regex.sub(\"^.-\", \"\", key) for key in unique_tags]))\n",
    "    return unique_tags, unique_types, tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1448912-d608-4943-9048-b23ba1fd0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(num_labels, model_name=\"GroNLP/bert-base-dutch-cased\"):\n",
    "    model = BertForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496f5c6-0704-4981-abaa-6f596fa3af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retokenize(text):\n",
    "    try:\n",
    "        return regex.sub(\" ##\", \"\", \" \".join(tokenizer.tokenize(\" \".join(nltk.word_tokenize(regex.sub(\"â€¦\",\"...\",text))))))\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374a8b0-2217-4cf5-a2ba-d443be2f82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_texts(texts, model, tokenizer):\n",
    "    ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "    results = []\n",
    "    failed_texts = []\n",
    "    for text in texts:\n",
    "        try:\n",
    "            results.append(ner_pipeline(retokenize(text)))\n",
    "        except:\n",
    "            results.append([])\n",
    "            failed_texts.append(f\"analysis failed for text: {text}\")\n",
    "        if len(results) % 10 == 0:\n",
    "            squeal(f\"{len(texts)}:{len(results)}\")\n",
    "    squeal(f\"{len(texts)}:{len(results)}\")\n",
    "    if len(failed_texts) > 0:\n",
    "        for failed_text in failed_texts:\n",
    "            print(failed_text)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c216c06-a2cf-4db9-bddd-14d69e77ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_ids(label_ids):\n",
    "    return [ id2tag[label_id] for label_id in label_ids if label_id != IGNORE_TAG_ID ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ea655-26c3-44d7-8993-328e9f5f598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_tokens_from_results(sentence_result):\n",
    "    return [ token_result[\"word\"] for token_result in sentence_result ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31998f81-a080-406b-82c2-91e939935385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_results(sentence_result):\n",
    "    return get_labels_from_ids([ int(regex.sub(\"^LABEL_\", \"\", token_result[\"entity\"])) for token_result in sentence_result ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f5f55-d2d7-4a19-b007-ecd00dd29f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_entities(tag_id_list, token_id_list):\n",
    "    entities = []\n",
    "    token_counter = 0\n",
    "    current_tag_class = \"\"\n",
    "    current_tag_start = -1\n",
    "    for tag, token in zip(tag_id_list, token_id_list):\n",
    "        tag_start = tag[0]\n",
    "        tag_class = regex.sub(r\"^[BI]-\", \"\", tag)\n",
    "        if regex.search(r\"^##\", token):\n",
    "            token_counter -= 1\n",
    "        if current_tag_class != \"\" and not regex.search(r\"^##\", token):\n",
    "            if tag_class == \"O\" or tag_start == \"B\" or tag_class != current_tag_class:\n",
    "                entities.append([current_tag_start, token_counter, current_tag_class])\n",
    "                current_tag_class = \"\"\n",
    "                current_tag_start = -1\n",
    "        if tag_class != \"O\" and current_tag_class == \"\":\n",
    "            current_tag_class = tag_class\n",
    "            current_tag_start = token_counter\n",
    "            if regex.search(r\"^##\", token) and (len(entities) == 0 or entities[-1][2] != token_counter):\n",
    "                current_tag_class = tag_class\n",
    "                current_tag_start = token_counter - 1\n",
    "        token_counter += 1\n",
    "    if current_tag_class != \"\":\n",
    "        entities.append([current_tag_start, token_counter, current_tag_class])\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb636d-53e5-4f3d-ad99-89e689cff209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_split_tokens(split_tokens):\n",
    "    combined_tokens = []\n",
    "    for token in split_tokens:\n",
    "        if not regex.search(r\"^##\", token):\n",
    "            combined_tokens.append(token)\n",
    "        else:\n",
    "            combined_tokens[-1] += regex.sub(r\"^##\", \"\", token)\n",
    "    return combined_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae386d-3cd0-487f-b894-8487ae1f1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_id_entities_to_char_id_entities(token_id_entities, split_tokens):\n",
    "    char_id_entities = []\n",
    "    tokens = combine_split_tokens(split_tokens)\n",
    "    for token_id_entity in token_id_entities:\n",
    "        char_start = 0\n",
    "        for i in range(0, token_id_entity[0]):\n",
    "            char_start += len(tokens[i]) + 1\n",
    "        char_end = char_start\n",
    "        for i in range(token_id_entity[0], token_id_entity[1]):\n",
    "            char_end += len(tokens[i]) + 1\n",
    "        char_id_entities.append([char_start, char_end - 1, token_id_entity[2]])\n",
    "    return char_id_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971b7c2-a6f0-43c4-8d74-bff2546ba8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognized_entities_to_annotation_labels(entities):\n",
    "    split_tokens = get_split_tokens_from_results(entities)\n",
    "    labels = get_labels_from_results(entities)\n",
    "    token_id_entities = results_to_entities(labels, split_tokens)\n",
    "    char_id_entities = token_id_entities_to_char_id_entities(token_id_entities, split_tokens)\n",
    "    return char_id_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7906ddc-ac42-43ef-ac4b-764bb6efbbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(results, data):\n",
    "    for data, result in zip(data.items(), results):\n",
    "        index, text = data\n",
    "        text = retokenize(text)\n",
    "        labels = recognized_entities_to_annotation_labels(result)\n",
    "        print(text, labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d245e11-6bde-4147-8130-b1c945a4b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags, unique_types, tag2id = make_tags(id2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d5de4-df07-4d30-9c29-0f62b513fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model(num_labels=len(unique_tags), model_name=\"models/2000b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84725216-b248-4bcf-ba25-97ee4eb2752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data[\"note_txt\"].values[:10]\n",
    "results = process_texts(data_sample, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dfb21a-ca3a-463b-98ed-0616fbafd404",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, result in zip(data_sample, results):\n",
    "    text = retokenize(text)\n",
    "    labels = recognized_entities_to_annotation_labels(result)\n",
    "    entities = [ { \"start\": start, \"end\": end, \"entity\": \"B-\"+label} for start, end, label in labels ] \n",
    "    ner_analysis_process.render_text(text, entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d143a65-8e0e-4421-9e14-ff4fd70e07c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
