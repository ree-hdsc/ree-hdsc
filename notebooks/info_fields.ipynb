{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9c3230-798b-43f4-a3f4-a96ad3f18dc2",
   "metadata": {},
   "source": [
    "# Info fields\n",
    "\n",
    "Extract persons from the info fields StartEntryInfo and EndEntryInfo of the [slave registers of Suriname](https://datasets.iisg.amsterdam/dataset.xhtml?persistentId=hdl:10622/CSPBHO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50668a0b-3088-4428-b62b-31e21cf0624f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import regex\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "from scripts import get_deceased_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977e92a-a650-477a-8d20-9586820b8a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def squeal(text=None):\n",
    "    clear_output(wait=True)\n",
    "    if not text is None: \n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef938b3-c035-43c8-b692-00dd3d3609c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_FILE = \"../../data/suriname/Dataset Suriname Slave and Emancipation Registers Version 1.1.csv\"\n",
    "\n",
    "data = pd.read_csv(DATA_FILE, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ea563-1bd7-415c-994f-444ed175927e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"StartEntryEventDetailed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee273a1-f642-4736-8c5b-ee6d75aee234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_previous_token(text, entity):\n",
    "    previous_token = \"\"\n",
    "    end = entity[\"start\"] - 1\n",
    "    while end > 0 and regex.search(\"\\s\", text[end-1]):\n",
    "        end -= 1\n",
    "    start = end - 1\n",
    "    while start > 0 and not regex.search(\"\\s\", text[start-1]):\n",
    "        start -= 1\n",
    "    if end >= 0:\n",
    "        previous_token = text[start: end]\n",
    "    return previous_token, start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3897f1-7296-4d2d-b48e-f10384c3785c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Van H M Beekman voor 1/4. Van M M Beekman voor 1/4. Van den boedel I E van Wijck geboren Beekman voor 1/4. En van den boedel G F C Beekman voor het overige 1/4.\"\n",
    "entities = get_deceased_name.run_bert_pipeline(text)\n",
    "get_deceased_name.combine_entities(get_deceased_name.expand_entities(entities, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee086448-69c3-457c-bc76-732209e3acee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MISSING_WORDS = [ \"erven\", \"geb\", \"geboren\", \"weduwe\", ]\n",
    "\n",
    "def get_names_from_data(data):\n",
    "    names = []\n",
    "    last_index = -1\n",
    "    last_end = -1\n",
    "    for index, row in data.iterrows():\n",
    "        text = row[\"StartEntryInfo\"]\n",
    "        try:\n",
    "            entities = get_deceased_name.run_bert_pipeline(text)\n",
    "            entities = get_deceased_name.combine_entities(get_deceased_name.expand_entities(entities, text))\n",
    "            if len(entities) > 0:\n",
    "                for entity in entities:\n",
    "                    if regex.search(\"PERSON\", entity[\"entity\"]):\n",
    "                        previous_token, start = get_previous_token(text, entity)\n",
    "                        if previous_token.lower() in MISSING_WORDS:\n",
    "                            entity[\"start\"] = start\n",
    "                        name_string = text[entity[\"start\"]: entity[\"end\"]]\n",
    "                        if regex.search(\"^geb\", name_string) and index == last_index and entity[\"start\"] == last_end + 1:\n",
    "                            names[-1] = (names[-1][0], names[-1][1] + \" \" + name_string)\n",
    "                        names.append((index, text[entity[\"start\"]: entity[\"end\"]]))\n",
    "                        last_end = entity[\"end\"]\n",
    "                        last_index = index\n",
    "        except:\n",
    "            pass\n",
    "        if index % 100 == 0:\n",
    "            squeal(index)\n",
    "        if len(names) >= 1000:\n",
    "            break\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf5729-0059-47b7-90f2-288a80539eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = get_names_from_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d092746-0e85-4ded-bd25-293f847f59e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56111af-333a-44d3-9bc8-8b433af94dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefixes_to_delete = [ \"boedel\", \"en\", ]\n",
    "suffixes_to_delete = [ \"beh.\", \"bij executie\", \"dd\", \"per executie\", \"qq\", \"voor den vrijdom\", ]\n",
    "non_names = [ \"den lande\", \"janij\", \"t\", ]\n",
    "\n",
    "def get_names_from_string(name_string):\n",
    "    names = []\n",
    "    for non_name in non_names:\n",
    "        match = regex.search(f\"^{non_name}$\", name_string, regex.IGNORECASE)\n",
    "        if match:\n",
    "            return []\n",
    "    for prefix in prefixes_to_delete:\n",
    "        match = regex.search(f\"^(.*)\\s+{prefix}\\s+(.*)$\", name_string, regex.IGNORECASE)\n",
    "        if match:\n",
    "            names.extend(get_names_from_string(match.group(1)))\n",
    "            names.extend(get_names_from_string(match.group(2)))\n",
    "            return names\n",
    "        match = regex.search(f\"^{prefix}\\s+(.*)$\", name_string, regex.IGNORECASE)\n",
    "        if match:\n",
    "            return get_names_from_string(match.group(1))\n",
    "    for suffix in suffixes_to_delete:\n",
    "        match = regex.search(f\"^(.*)\\s+{suffix}\\s+(.*)$\", name_string, regex.IGNORECASE)\n",
    "        if match:\n",
    "            names.extend(get_names_from_string(match.group(1)))\n",
    "            names.extend(get_names_from_string(match.group(2)))\n",
    "            return names\n",
    "        match = regex.search(f\"^(.*)\\s+{suffix}$\", name_string, regex.IGNORECASE)\n",
    "        if match:\n",
    "            return get_names_from_string(match.group(1))\n",
    "    names.append(name_string)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69540fc2-55f2-4807-9ecf-b0cdd5ede5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup_name(name_string):\n",
    "    name_string = regex.sub(\"[.,]\\s*\", \" \", name_string)\n",
    "    return name_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef6ced-2bd7-4f3f-8130-e6adafb3e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"StartEntryInfo\"][557]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321cdf6-d9c9-4923-8c37-5e9f58897ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_name_words = [ \"d\", \"da\", \"de\", \"den\", \"der\", \"geb\", \"geboren\", \"v\", \"van\" ]\n",
    "\n",
    "def split_name(name_string):\n",
    "    name_tokens = name_string.split()\n",
    "    first_name_tokens = name_tokens[:-1]\n",
    "    last_name_tokens = name_tokens[-1:]\n",
    "    for i in range(0, len(first_name_tokens)):\n",
    "        if first_name_tokens[i].lower() in last_name_words and (not len(first_name_tokens[i]) or first_name_tokens[i].lower() == first_name_tokens[i]):\n",
    "            while len(first_name_tokens) > i:\n",
    "                last_name_tokens = [ first_name_tokens.pop(-1)] + last_name_tokens\n",
    "            break\n",
    "    return \" \".join(first_name_tokens), \" \".join(last_name_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec5d8d-ec4a-4b1a-b0ff-9dfd8bfd2948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0, 100):\n",
    "    if isinstance(data[\"StartEntryInfo\"][i], str):\n",
    "        print(data[\"StartEntryInfo\"][i])\n",
    "        for j in range(0, 100):\n",
    "            if names[j][0] == i:\n",
    "                for name_string in get_names_from_string(cleanup_name(names[j][1])):\n",
    "                    print(\"   \", i, split_name(name_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86023b5f-358a-4576-b4d0-dd239a83fbb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name_tuple in names:\n",
    "    for name_string in get_names_from_string(cleanup_name(name_tuple[1])):\n",
    "        print(name_tuple[0], split_name(name_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8de166-693f-47a0-9daf-588863ce855c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
