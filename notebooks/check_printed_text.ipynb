{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd81a94-b1e3-4004-b7ef-9fdfa90cafb4",
   "metadata": {},
   "source": [
    "# Check printed text\n",
    "\n",
    "Find the expected printed text in a certificate, check for errror and make suggestions for changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250639cd-c19e-4b0b-ac60-6ff5ccff8a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import regex\n",
    "import sys\n",
    "from spacy import displacy\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "from scripts import read_transkribus_files, printed_text, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0937d2a-683c-4eed-8e82-f79796de410a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def render_text(text, entities):\n",
    "    displacy.render({ \"text\": re.sub(\"\\\\n\", \" \", text), \n",
    "                      \"ents\": entities }, \n",
    "                      options = { \"colors\": { \"fuzzy_match\": \"yellow\"} }, style = \"ent\", manual = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f9ff0-f79d-4988-b9e8-1af7d46a9de2",
   "metadata": {},
   "source": [
    "## 1. Find missed printed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e65fd0-7729-4836-8731-ac1ac46ed42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data/Overlijden/x-samples/three-columns-100/page\"\n",
    "\n",
    "texts, metadata, textregions = read_transkribus_files.read_files(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f584523e-9e2c-4693-8ae0-f90c9718888e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_printed_text_year(text_id):\n",
    "    \"\"\" finds appropriate index of text format printed_text.PRINTED_TEXT for a certificate \"\"\"\n",
    "    text_year = int(text_id[:4])\n",
    "    printed_text_year = list(printed_text.PRINTED_TEXT.keys())[0]\n",
    "    for year in sorted(printed_text.PRINTED_TEXT.keys()):\n",
    "        if year > printed_text_year and text_year >= year:\n",
    "            printed_text_year = year\n",
    "    return printed_text_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff139e-1570-47ba-83ce-dab32839cab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def same_number_of_words(phrase, search_text, positions):\n",
    "    \"\"\" check if the proposed replacement phrase has the same number of words as the original \"\"\"\n",
    "    guessed_phrase = search_text[positions[0].start(): positions[0].end()]\n",
    "    return len(guessed_phrase.split()) == len(phrase.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb4499-0ae3-4852-86ce-67af9a84e091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SKIP_PHRASES = [ \"des jaars een duizend acht honderd\", \"op dit eiland\", \"op den\", ]\n",
    "\n",
    "def find_match(text, phrase, start=0, end=None, level=0, max_diff=3):\n",
    "    \"\"\" find a phrase in the text allowing for some (max_diff) non-matching characters \"\"\"\n",
    "    match = {}\n",
    "    search_text = text[start: end]\n",
    "    if phrase.lower() in SKIP_PHRASES and start == 0 and end == None:\n",
    "        return match\n",
    "    if len(phrase) > 2 - level:\n",
    "        positions = utils.find_text_patterns(phrase.lower(), search_text.lower())\n",
    "        if (len(positions) == 1 and \n",
    "            (positions[0][\"start\"] == 0 or \n",
    "             not regex.search(\"[a-z]\", search_text[positions[0][\"start\"]-1].lower())) and \n",
    "            (positions[0][\"end\"] == len(search_text) or \n",
    "             not regex.search(\"[a-z]\", search_text[positions[0][\"end\"]].lower()))):\n",
    "            positions[0][\"label\"] = phrase\n",
    "            match = { \"start\": positions[0][\"start\"] + start,\n",
    "                      \"end\": positions[0][\"end\"] + start,\n",
    "                      \"label\": \"match\" } # positions[0][\"label\"] }\n",
    "        elif len(positions) == 0:\n",
    "            character_errors = 0\n",
    "            while len(positions) == 0 and character_errors <= max_diff:\n",
    "                query = f\"({phrase.lower()})\"+\"{\"+f\"e<={character_errors}\"+\"}\"\n",
    "                positions = [ match for match in regex.finditer(query, search_text.lower()) ]\n",
    "                character_errors += 1\n",
    "            if len(positions) == 1 and same_number_of_words(phrase, search_text, positions):\n",
    "                match = { \"start\": positions[0].start() + start,\n",
    "                          \"end\": positions[0].end() + start,\n",
    "                          \"label\": \"fuzzy_match\",\n",
    "                          \"correct_phrase\": phrase }\n",
    "                if positions[0].group()[0] == \" \":\n",
    "                    match[\"start\"] += 1\n",
    "                if positions[0].group()[-1] == \" \":\n",
    "                    match[\"end\"] -= 1\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152b3dc-67f2-4cf1-adc2-1c61ffb22b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_phrases_in_text(text, phrases):\n",
    "    \"\"\" find phrases in text, only return unique matches \"\"\"\n",
    "    entities = []\n",
    "    for phrase in phrases:\n",
    "        entities.append(find_match(text, phrase))\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7e1c5-6ed9-402e-8f9b-14bcd68fd5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_min_char_pos(entities, index):\n",
    "    \"\"\" get the final position of the last preceding phrase with a match \"\"\"\n",
    "    for counter in range(index-1, 0, -1):\n",
    "        if \"end\" in entities[counter]:\n",
    "            return entities[counter][\"end\"] + 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4052123-10f4-40a0-bdcb-70420a2c4ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_max_char_pos(entities, index):\n",
    "    \"\"\" get the first position of the first next phrase with a match \"\"\"\n",
    "    for counter in range(index+1, len(entities)):\n",
    "        if \"start\" in entities[counter]:\n",
    "            return entities[counter][\"start\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd87a1-80f1-4777-925a-cb9571ddde56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_phrases_in_text_with_entities(text, phrases, entities, max_diff=3):\n",
    "    \"\"\" find phrases in text, only return unique matches \"\"\"\n",
    "    for i in range(0, len(phrases)):\n",
    "        if len(entities[i]) == 0:\n",
    "            start = get_min_char_pos(entities, i)\n",
    "            end = get_max_char_pos(entities, i)\n",
    "            if end == None:\n",
    "                entities[i] = find_match(text, phrases[i], start=start, level=1, max_diff=max_diff)\n",
    "            else:\n",
    "                entities[i] = find_match(text, phrases[i], start=start, end=end, level=1, max_diff=max_diff)                \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3be37a-631e-481f-8943-2f142eceb914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_entities(entities, entity_replaced):\n",
    "    \"\"\" adjust start and end point of entities after replacing a text \"\"\"\n",
    "    delta = len(entity_replaced[\"correct_phrase\"]) - (entity_replaced[\"end\"] - entity_replaced[\"start\"])\n",
    "    for entity in entities:\n",
    "        if \"start\" in entity and entity[\"start\"] > entity_replaced[\"start\"]:\n",
    "            entity[\"start\"] += delta\n",
    "        if \"end\" in entity and entity[\"end\"] >= entity_replaced[\"end\"]:\n",
    "            entity[\"end\"] += delta\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587719de-d85f-42da-be0d-e0cf241bd6fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_text(text_in, entities):\n",
    "    \"\"\" replace fuzzy matches in text by correct phrases \"\"\"\n",
    "    text_out = text_in\n",
    "    for entity in reversed(entities):\n",
    "        if \"label\" in entity and entity[\"label\"] == \"fuzzy_match\":\n",
    "            text_out = text_out[:entity[\"start\"]] + entity[\"correct_phrase\"] + text_out[entity[\"end\"]:]\n",
    "            if len(entity[\"correct_phrase\"]) != entity[\"end\"] - entity[\"start\"]:\n",
    "                entities = update_entities(entities, entity)\n",
    "    return text_out, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9ea58-317f-4928-b1b7-af364d635b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NO_SPLIT_PHRASES = [ \"des jaars een duizend acht honderd\", \n",
    "                     \"laatstelijk gewoond\", \n",
    "                     \"niet te kunnen schrijven\", \n",
    "                     \"op dit eiland\" ]\n",
    "\n",
    "def printed_text_split_in_words(printed_text_in, entities_in):\n",
    "    \"\"\" split expected phrase in word before searching word-by-word \"\"\"\n",
    "    printed_text_out = []\n",
    "    entities_out = []\n",
    "    for i in range(0, len(printed_text_in)):\n",
    "        if len(entities[i]) > 0 or len(printed_text_in[i].split()) == 1 or printed_text_in[i].lower() in NO_SPLIT_PHRASES:\n",
    "            printed_text_out.append(printed_text_in[i])\n",
    "            entities_out.append(entities_in[i])\n",
    "        else:\n",
    "            for word in printed_text_in[i].split():\n",
    "                printed_text_out.append(word)\n",
    "                entities_out.append({})\n",
    "    return printed_text_out, entities_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a572ba-d003-4ecc-aac9-8dd5d341665a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sanity_check_entities(entities, text_id):\n",
    "    starts_seen = {}\n",
    "    ends_seen = {}\n",
    "    for entity in entities:\n",
    "        if \"start\" in entity:\n",
    "            if entity[\"start\"] in starts_seen:\n",
    "                utils.print_with_color(f\"duplicate start: {entity['start']} for text_id {text_id}!!\\n\")\n",
    "            if entity[\"end\"] in ends_seen:\n",
    "                utils.print_with_color(f\"duplicate end: {entity['end']} for text_id {text_id}!\\n\")\n",
    "                sys.exit()\n",
    "            starts_seen[entity[\"start\"]] = True\n",
    "            ends_seen[entity[\"end\"]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e63385-e3aa-464d-b55a-cb74efcfcdac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrected_text = {}\n",
    "text_entities = {}\n",
    "for text_id in sorted(texts.keys()):\n",
    "    if text_id > \"0\":\n",
    "        printed_text_year = get_printed_text_year(text_id)\n",
    "        printed_text_text = printed_text.PRINTED_TEXT[printed_text_year]\n",
    "        entities = find_phrases_in_text(texts[text_id], printed_text_text)\n",
    "        entities = find_phrases_in_text_with_entities(texts[text_id], printed_text_text, entities)\n",
    "        entities = find_phrases_in_text_with_entities(texts[text_id], printed_text_text, entities)\n",
    "        printed_text_text, entities = printed_text_split_in_words(printed_text_text, entities)\n",
    "        entities = find_phrases_in_text_with_entities(texts[text_id], printed_text_text, entities)\n",
    "        entities = find_phrases_in_text_with_entities(texts[text_id], printed_text_text, entities)\n",
    "        sanity_check_entities(entities, text_id)\n",
    "        text_entities[text_id] = entities\n",
    "        corrected_text[text_id], entities = correct_text(texts[text_id], copy.deepcopy(entities))\n",
    "        print(text_id)\n",
    "        render_text(corrected_text[text_id], [ entity for entity in entities if \"label\" in entity ])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c19571-c1b9-41d8-a450-d263e8f4c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(corrected_text, orient=\"index\").to_csv(\"three_columns_100_corrected.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c103d-5242-41d0-b8ef-4fc57c1f0b8a",
   "metadata": {},
   "source": [
    "## 2. Correct XML text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e22885-b891-43e8-b85f-bd440ee1a309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f15dd-0676-471e-96de-052e0c2fcc06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_text_entities(text_entities):\n",
    "    \"\"\" verify that there are not text correction with a different number of words than the original \"\"\"\n",
    "    for text_id in text_entities:\n",
    "        for entity in sorted([x for x in text_entities[text_id] if len(x) > 0 ], key=lambda x: x[\"start\"]):\n",
    "            if \"correct_phrase\" in entity:\n",
    "                guessed_phrase = texts[text_id][entity[\"start\"]:entity[\"end\"]]\n",
    "                correct_phrase = entity[\"correct_phrase\"]\n",
    "                if not (len(guessed_phrase.split()) == \n",
    "                        len(correct_phrase.split())):\n",
    "                    print(text_id, guessed_phrase, \"#\", correct_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ac45a-c5d6-413f-a39c-a391f38f1958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_text_entities(entities):\n",
    "    corrected_tokens = {}\n",
    "    for entity in entities:\n",
    "        if \"label\" in entity and entity[\"label\"] == \"fuzzy_match\":\n",
    "            offset = entity[\"start\"]\n",
    "            for token in entity[\"correct_phrase\"].split():\n",
    "                corrected_tokens[offset] = token\n",
    "                offset += len(token) + 1\n",
    "    return corrected_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0eb88e-386a-4b98-99e8-6c2b40e4a55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = \"../../data/Overlijden/x-samples/three-columns-100/page/O.R. 1831 Stad 027.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98604b24-4075-4c17-8b72-ab88d3b7e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(file_name, tree):\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        tree.write(f, encoding=\"utf8\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b350b-16df-4064-8117-f859b4137301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup_xml_file(file_name):\n",
    "    file_handle_in = open(file_name, \"r\")\n",
    "    buffer = \"\"\n",
    "    for line in file_handle_in:\n",
    "        line = regex.sub(\"encoding=.utf8.\", 'encoding=\"UTF-8\" standalone=\"yes\"', line)\n",
    "        line = regex.sub(\"ns0:\", \"\", line)\n",
    "        buffer += regex.sub(\":ns0\", \"\", line)\n",
    "    file_handle_in.close()\n",
    "    file_handle_out = open(file_name, \"w\")\n",
    "    print(buffer, file=file_handle_out)\n",
    "    file_handle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc2abc-d693-437d-9cca-5adfeecb2f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_file(file_name, text_entities):\n",
    "    text_id = read_transkribus_files.make_file_id(file_name)\n",
    "    print(text_id)\n",
    "    corrected_tokens = convert_text_entities(text_entities[text_id])\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "    counter = 0\n",
    "    for textline in root.findall(\".//{*}TextLine\"):\n",
    "        changed = False\n",
    "        changed_line = \"\"\n",
    "        for unicode in textline.findall(\"./{*}Word/{*}TextEquiv/{*}Unicode\"):\n",
    "            next_counter = counter + 1 + len(unicode.text)\n",
    "            corrected_token = \"\"\n",
    "            if counter in corrected_tokens and corrected_tokens[counter].lower() != unicode.text.lower():\n",
    "                corrected_token = corrected_tokens[counter]\n",
    "                utils.print_with_color(f\"{counter} {unicode.text} {corrected_token}\\n\")\n",
    "                unicode.text = corrected_token\n",
    "                changed = True\n",
    "            if len(changed_line) == 0:\n",
    "                changed_line = unicode.text\n",
    "            else:\n",
    "                changed_line += \" \" + unicode.text\n",
    "            counter = next_counter\n",
    "        for unicode in textline.findall(\"./{*}TextEquiv/{*}Unicode\"):\n",
    "            if changed:\n",
    "                unicode.text = changed_line\n",
    "    file_name_corrected = regex.sub(\"/page/\", \"/corrected/\", file_name)\n",
    "    write_file(file_name_corrected, tree)\n",
    "    cleanup_xml_file(file_name_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d46802-bb6c-4114-a085-2c85c98b92bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"../../data/Overlijden/x-samples/three-columns-100/page/\"\n",
    "\n",
    "for text_id in text_entities:\n",
    "    file_name = base_dir + read_transkribus_files.make_file_name(text_id, base_dir)\n",
    "    correct_file(file_name, text_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338cd3a-f6f1-483d-b199-0a8fe5cb0e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
